{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514acb34-482c-4bb6-b313-65625b57d46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import pathlib\n",
    "import hashlib\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Dotenv\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "import visualkeras\n",
    "from PIL import ImageFont\n",
    "from collections import defaultdict\n",
    "\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_unet import *\n",
    "from utils.utils_resnet import *\n",
    "from utils.utils_plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab302ceb-a119-482b-ba1c-38c26f465fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Paths\n",
    "PATH_ERA5 = config['PATH_ERA5']\n",
    "PATH_EOBS = config['PATH_EOBS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ebd096-d72a-4f1a-a3ff-c156b74ac5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cropping=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4a4299-aa55-4dff-a019-82e4ebc45dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_models = os.listdir('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837bfc21-e15e-46f4-a401-79625be25b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d974fb1e-af89-4f06-93bd-68a184ca3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is extremely slow!\n",
    "#reconstructed_model = tf.keras.models.load_model('tmp/' + l_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4bb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFactory(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Model factory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, arch, input_size, output_size, for_extremes=False, latent_dim=128, dropout_rate=0.2, \n",
    "                 use_batch_norm=True, inner_activation='relu', output_scaling=1, output_crop=None):\n",
    "        super(DeepFactory, self).__init__()\n",
    "        self.arch = arch\n",
    "        self.input_size = list(input_size)\n",
    "        self.output_size = list(output_size)\n",
    "        self.for_extremes = for_extremes\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.inner_activation = inner_activation\n",
    "        self.output_scaling = output_scaling\n",
    "        self.output_crop = output_crop\n",
    "        \n",
    "        self.last_activation = 'relu'\n",
    "        if for_extremes:\n",
    "            self.last_activation = 'sigmoid'\n",
    "\n",
    "        if arch == 'Davenport-2021':\n",
    "            self.build_Davenport_2021()\n",
    "        elif arch == 'CNN-2L':\n",
    "            self.build_CNN_2L()\n",
    "        elif arch == 'Unet':\n",
    "            self.build_Unet()\n",
    "        elif arch == 'Pan-2019':\n",
    "            self.build_Pan_2019()\n",
    "        elif arch =='Conv-LTSM':\n",
    "            self.build_convLTSM()\n",
    "        else:\n",
    "            raise ValueError('The architecture was not correctly defined')\n",
    "        \n",
    "        \n",
    "    def build_Davenport_2021(self):\n",
    "        \"\"\"\n",
    "        Based on: Davenport, F. V., & Diffenbaugh, N. S. (2021). Using Machine Learning to \n",
    "        Analyze Physical Causes of Climate Change: A Case Study of U.S. Midwest Extreme Precipitation. \n",
    "        Geophysical Research Letters, 48(15). https://doi.org/10.1029/2021GL093787\n",
    "        \"\"\"\n",
    "        \n",
    "        # Downsampling\n",
    "        inputs = layers.Input(shape=self.input_size)\n",
    "        x = layers.Conv2D(16, 3, padding='same', activity_regularizer=regularizers.l2(0.01))(inputs)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "        x = layers.SpatialDropout2D(self.dropout_rate)(x) # In original: simple Dropout\n",
    "        x = layers.Conv2D(16, 3, padding='same', activity_regularizer=regularizers.l2(0.01))(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "        x = layers.SpatialDropout2D(self.dropout_rate)(x) # In original: simple Dropout\n",
    "        x = layers.Flatten()(x)                \n",
    "        x = layers.Dense(self.latent_dim, activity_regularizer=regularizers.l2(0.001))(x) # In original: 16\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        next_shape = self.get_shape_for(stride_factor=4)\n",
    "\n",
    "        # Upsampling. In original: no decoder\n",
    "        x = self.dense_block(x, np.prod(next_shape))\n",
    "        x = layers.Reshape(target_shape=next_shape)(x)\n",
    "        x = self.deconv_block(x, 16, 3, stride=2)\n",
    "        x = self.deconv_block(x, 16, 3, stride=2)\n",
    "        x = self.conv_block(x, 1, 3, activation=self.last_activation)\n",
    "        outputs = self.final_cropping_block(x)\n",
    " \n",
    "        self.model = keras.Model(inputs, outputs, name=\"Davenport-2021\")\n",
    "        \n",
    "        \n",
    "    def build_Pan_2019(self):\n",
    "        \"\"\"\n",
    "        Based on: Pan, B., Hsu, K., AghaKouchak, A., & Sorooshian, S. (2019). \n",
    "        Improving Precipitation Estimation Using Convolutional Neural Network. \n",
    "        Water Resources Research, 55(3), 2301–2321. https://doi.org/10.1029/2018WR024090\n",
    "        \"\"\"\n",
    "        # In original: padding='valid'\n",
    "        \n",
    "        # Downsampling\n",
    "        inputs = layers.Input(shape=self.input_size)\n",
    "        x = layers.Conv2D(15, 4, padding='same')(inputs)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(20, 4, padding='same')(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "        x = layers.Conv2D(20, 4, padding='same')(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(self.latent_dim, activation='relu')(x) # In original: 60\n",
    "\n",
    "        next_shape = self.get_shape_for(stride_factor=4)\n",
    "\n",
    "        # Upsampling. In original: no decoder\n",
    "        x = self.dense_block(x, np.prod(next_shape))\n",
    "        x = layers.Reshape(target_shape=next_shape)(x)\n",
    "        x = self.deconv_block(x, 20, 4, stride=2)\n",
    "        x = self.deconv_block(x, 20, 4, stride=2)\n",
    "        x = self.conv_block(x, 15, 4)\n",
    "        x = self.conv_block(x, 1, 3, activation=self.last_activation)\n",
    "        outputs = self.final_cropping_block(x)\n",
    "\n",
    "        self.model = keras.Model(inputs, outputs, name=\"Pan-2019\")\n",
    "\n",
    "\n",
    "    def build_CNN_2L(self):\n",
    "\n",
    "        # Downsampling\n",
    "        inputs = layers.Input(shape=self.input_size)\n",
    "        x = self.conv_block(inputs, 32, 3, stride=2, with_batchnorm=True, with_dropout=True)\n",
    "        x = self.conv_block(x, 64, 3, stride=2, with_batchnorm=True, with_dropout=True)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense_block(x, self.latent_dim, activation='sigmoid')\n",
    "\n",
    "        next_shape = self.get_shape_for(stride_factor=4)\n",
    "\n",
    "        # Upsampling\n",
    "        x = self.dense_block(x, np.prod(next_shape))\n",
    "        x = layers.Reshape(target_shape=next_shape)(x)\n",
    "        x = self.deconv_block(x, 64, 3, stride=2)\n",
    "        x = self.deconv_block(x, 32, 3, stride=2)\n",
    "        x = self.deconv_block(x, 1, 3, activation=self.last_activation)\n",
    "        outputs = self.final_cropping_block(x)\n",
    "\n",
    "        self.model = keras.Model(inputs, outputs, name=\"CNN-v1\")\n",
    "        \n",
    "\n",
    "    def build_convLTSM(self):\n",
    "        \n",
    "        expanded_shape = self.input_size.copy()\n",
    "        expanded_shape.insert(0, 1)\n",
    "        \n",
    "        inputs = layers.Input(shape=self.input_size)\n",
    "        \n",
    "        x = layers.Reshape(target_shape=expanded_shape)(inputs)\n",
    "        \n",
    "        x = layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), return_sequences=True, padding = 'same',\n",
    "                              go_backwards=True, activation='tanh', data_format = 'channels_last',\n",
    "                              dropout=0.4, recurrent_dropout=0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.ConvLSTM2D(filters=16, kernel_size=(3, 3), return_sequences=True, padding = 'same',\n",
    "                              go_backwards=True, activation='tanh', data_format = 'channels_last',\n",
    "                              dropout=0.4, recurrent_dropout=0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.ConvLSTM2D(filters=8, kernel_size=(3, 3), return_sequences=False, padding = 'same',\n",
    "                              go_backwards=True, activation='tanh', data_format = 'channels_last',\n",
    "                              dropout=0.3, recurrent_dropout=0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu', data_format='channels_last')(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "        #model.add(Flatten())\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.25)(x)\n",
    "\n",
    "        x = layers.Conv2DTranspose(filters=1, kernel_size=(1, 1), strides=(2, 2),  activation='sigmoid',\n",
    "                                   padding='same', data_format='channels_last')(x)\n",
    "\n",
    "        outputs = self.final_cropping_block(x)\n",
    "\n",
    "        self.model = keras.Model(inputs, outputs, name=\"Conv-LTSM\")\n",
    "        \n",
    "        \n",
    "    def build_Unet(self):\n",
    "        \"\"\"\n",
    "        Based on: U-Net: https://github.com/nikhilroxtomar/Unet-for-Person-Segmentation/blob/main/model.py\n",
    "        \"\"\"\n",
    "        \n",
    "        filters_nb = 64\n",
    "        \n",
    "        # Downsampling\n",
    "        inputs = layers.Input(shape=self.input_size)\n",
    "        \n",
    "        # Pad if necessary\n",
    "        x = self.padding_block(inputs, factor=16)\n",
    "        \n",
    "        s1, p1 = self.unet_encoder_block(x, filters_nb)\n",
    "        s2, p2 = self.unet_encoder_block(p1, filters_nb * 2)\n",
    "        s3, p3 = self.unet_encoder_block(p2, filters_nb * 4)\n",
    "        s4, p4 = self.unet_encoder_block(p3, filters_nb * 8)\n",
    "        \n",
    "        x = self.conv_block(p4, filters_nb * 16, 3, initializer='he_normal', with_batchnorm=True, with_dropout=True)\n",
    "        b1 = self.conv_block(x, filters_nb * 16, 3, initializer='he_normal', with_batchnorm=True)\n",
    "\n",
    "        # Upsampling\n",
    "        d1 = self.unet_decoder_block(b1, s4, filters_nb * 8)\n",
    "        d2 = self.unet_decoder_block(d1, s3, filters_nb * 4)\n",
    "        d3 = self.unet_decoder_block(d2, s2, filters_nb * 2)\n",
    "        d4 = self.unet_decoder_block(d3, s1, filters_nb, is_last=True)\n",
    "        \n",
    "        # Additional upsampling for downscaling\n",
    "        x = self.handle_output_scaling(d4)\n",
    "\n",
    "        x = self.conv_block(x, 1, 1, activation=self.last_activation)\n",
    "        outputs = self.final_cropping_block(x)\n",
    "\n",
    "        self.model = keras.Model(inputs, outputs, name=\"U-Net-v1\")\n",
    "        \n",
    "        \n",
    "    def unet_encoder_block(self, input, filters, kernel_size=3):\n",
    "        x = self.conv_block(input, filters, kernel_size, initializer='he_normal', with_batchnorm=True, with_dropout=True)\n",
    "        x = self.conv_block(x, filters, kernel_size, initializer='he_normal', with_batchnorm=True)\n",
    "        p = layers.MaxPooling2D((2, 2))(x)\n",
    "        \n",
    "        return x, p\n",
    "\n",
    "    \n",
    "    def unet_decoder_block(self, input, skip_features, filters, conv_kernel_size=3, deconv_kernel_size=2, is_last=False):\n",
    "        x = self.deconv_block(input, filters, deconv_kernel_size, stride=2)\n",
    "        x = layers.Concatenate()([x, skip_features])\n",
    "        x = self.conv_block(x, filters, conv_kernel_size, initializer='he_normal', with_batchnorm=True, with_dropout=True)\n",
    "        x = self.conv_block(x, filters, conv_kernel_size, initializer='he_normal', with_batchnorm=(not is_last))\n",
    "\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def conv_block(self, input, filters, kernel_size=3, stride=1, padding='same', initializer='default', activation='default', \n",
    "                   with_batchnorm=False, with_pooling=False, with_dropout=False, with_late_activation=False):\n",
    "        if activation == 'default':\n",
    "            activation = self.inner_activation\n",
    "            \n",
    "        conv_activation = activation\n",
    "        if with_late_activation:\n",
    "            conv_activation = None\n",
    "            \n",
    "        if initializer == 'default':\n",
    "            x = layers.Conv2D(filters, kernel_size, strides=(stride, stride), padding=padding, activation=conv_activation)(input)\n",
    "        else:\n",
    "            x = layers.Conv2D(filters, kernel_size, strides=(stride, stride), padding=padding, activation=conv_activation, kernel_initializer=initializer)(input)\n",
    "            \n",
    "        if with_batchnorm:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        if with_late_activation:\n",
    "            x = layers.Activation(activation)(x)\n",
    "        if with_pooling:\n",
    "            x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "        if with_dropout:\n",
    "            x = layers.SpatialDropout2D(self.dropout_rate)(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def deconv_block(self, input, filters, kernel_size=3, stride=1, padding='same', initializer='default', activation='default', \n",
    "                     with_batchnorm=False, with_dropout=False):\n",
    "        if activation == 'default':\n",
    "            activation = self.inner_activation\n",
    "        \n",
    "        if initializer == 'default':\n",
    "            x = layers.Conv2DTranspose(filters, kernel_size, strides=stride, padding=padding, activation=activation)(input)\n",
    "        else:\n",
    "            x = layers.Conv2DTranspose(filters, kernel_size, strides=stride, padding=padding, activation=activation, kernel_initializer=initializer)(input)\n",
    "            \n",
    "        if with_batchnorm:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        if with_dropout:\n",
    "            x = layers.SpatialDropout2D(self.dropout_rate)(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def dense_block(self, input, units, activation='default', with_dropout=False):\n",
    "        if activation == 'default':\n",
    "            activation=self.inner_activation\n",
    "            \n",
    "        x = layers.Dense(units, activation=activation)(input)\n",
    "        if with_dropout:\n",
    "            x = layers.Dropout(self.dropout_rate)(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "    \n",
    "    def handle_output_scaling(self, input, with_batchnorm=False):\n",
    "        if self.output_scaling > 1:\n",
    "            if self.output_scaling == 2:\n",
    "                x = self.deconv_block(input, 64, 3, stride=2, with_batchnorm=with_batchnorm)\n",
    "            elif self.output_scaling == 3:\n",
    "                x = self.deconv_block(input, 64, 3, stride=3, with_batchnorm=with_batchnorm)\n",
    "            elif self.output_scaling == 4:\n",
    "                x = self.deconv_block(input, 64, 3, stride=2, with_batchnorm=with_batchnorm)\n",
    "                x = self.deconv_block(x, 64, 3, stride=2, with_batchnorm=with_batchnorm)\n",
    "            elif self.output_scaling == 5:\n",
    "                x = self.deconv_block(input, 64, 3, stride=3, with_batchnorm=with_batchnorm)\n",
    "                x = self.deconv_block(x, 64, 3, stride=2, with_batchnorm=with_batchnorm)\n",
    "            else:\n",
    "                raise NotImplementedError('Level of downscaling not implemented')\n",
    "        else:\n",
    "            x = input\n",
    "        \n",
    "        if self.output_crop:\n",
    "            raise NotImplementedError('Manual cropping not yet implemented')\n",
    "            \n",
    "        return x\n",
    "            \n",
    "        \n",
    "    def padding_block(self, x, factor):\n",
    "        h, w = x.get_shape().as_list()[1:3]\n",
    "        dh = 0\n",
    "        dw = 0\n",
    "        if h % factor > 0:\n",
    "            dh = factor - h % factor\n",
    "        if w % factor > 0:\n",
    "            dw = factor - w % factor\n",
    "        if dh > 0 or dw > 0:\n",
    "            top_pad = dh//2\n",
    "            bottom_pad = dh//2 + dh%2\n",
    "            left_pad = dw//2\n",
    "            right_pad = dw//2 + dw%2\n",
    "            x = layers.ZeroPadding2D(padding=((top_pad, bottom_pad), (left_pad, right_pad)))(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def final_cropping_block(self, x):\n",
    "        # Compute difference between reconstructed width and hight and the desired output size.\n",
    "        h, w = x.get_shape().as_list()[1:3]\n",
    "        h_tgt, w_tgt = self.output_size[:2]\n",
    "        dh = h - h_tgt\n",
    "        dw = w - w_tgt\n",
    "\n",
    "        if dh < 0 or dw < 0:\n",
    "            raise ValueError(f'Negative values in output cropping dh={dh} and dw={dw}')\n",
    "\n",
    "        # Add to decoder cropping layer and final reshaping\n",
    "        x = layers.Cropping2D(cropping=((dh//2, dh-dh//2), (dw//2, dw-dw//2)))(x)\n",
    "        #x = layers.Reshape(target_shape=self.output_size,)(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "    def get_shape_for(self, stride_factor):\n",
    "        next_shape = self.output_size.copy()\n",
    "        next_shape[0] = int(np.ceil(next_shape[0]/stride_factor))\n",
    "        next_shape[1] = int(np.ceil(next_shape[1]/stride_factor))\n",
    "\n",
    "        return next_shape\n",
    "\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.model(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e5b9b8-da11-4cf0-bbb6-7f532f33fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "          'Dav-orig': {'model': 'Davenport-2021', 'run': True,\n",
    "                       'opt_model': {'latent_dim': 16},\n",
    "                       'opt_optimizer': {'lr_method': 'Constant'}}, # original\n",
    "          'Dav-64': {'model': 'Davenport-2021', 'run': True,\n",
    "                     'opt_model': {'latent_dim': 64},\n",
    "                     'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'Pan-orig': {'model': 'Pan-2019', 'run': True,\n",
    "                       'opt_model': {'latent_dim': 60},\n",
    "                       'opt_optimizer': {'lr_method': 'Constant', 'lr': 1e-4}},\n",
    "          'CNN-2l': {'model': 'CNN-2L', 'run': True,\n",
    "                     'opt_model': {'latent_dim': 64},\n",
    "                     'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET': {'model': 'Unet', 'run': True,\n",
    "                   'opt_model': {'output_scaling': 1, 'output_crop': None},\n",
    "                   'opt_optimizer': {'lr_method': 'CosineDecay'}}\n",
    "         \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95aaafa2-6bac-4116-8286-d09a40cb2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for plotting\n",
    "i_shape = [46,56,10]\n",
    "o_shape = [46,56,1]\n",
    "opt_model = {'latent_dim': 128,\n",
    "             'dropout_rate': 0.2}\n",
    "opt_optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad610e7b-c6c5-4ed0-9aa0-369e2751e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davenport-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 09:41:26.901355: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-23 09:41:27.698058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10415 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davenport-2021\n",
      "Pan-2019\n",
      "CNN-2L\n",
      "Unet\n"
     ]
    }
   ],
   "source": [
    "l_mod=[]\n",
    "color_map = defaultdict(dict)\n",
    "color_map[Conv2D]['fill'] = 'orange'\n",
    "color_map[Dropout]['fill'] = 'silver'\n",
    "color_map[MaxPooling2D]['fill'] = 'red'\n",
    "color_map[Dense]['fill'] = 'blue'\n",
    "color_map[Flatten]['fill'] = 'purple'\n",
    "color_map[BatchNormalization]['fill'] = 'lightgreen'\n",
    "for m_id in models:\n",
    "    # Extract model name and options\n",
    "    model = models[m_id]['model']\n",
    "    print(model)\n",
    "    opt_model_i = models[m_id]['opt_model']\n",
    "    opt_optimizer_i = models[m_id]['opt_optimizer']\n",
    "    opt_model_new = opt_model.copy()\n",
    "    opt_model_new.update(opt_model_i)\n",
    "    opt_optimizer_new = opt_optimizer\n",
    "    \n",
    "    m = DeepFactory(model, i_shape, o_shape, for_extremes=False, **opt_model_new)\n",
    "    # Plot\n",
    "    #visualkeras.layered_view(m.model, legend=True,color_map=color_map,\n",
    "    #                     type_ignore=[ZeroPadding2D, Reshape, Dropout, BatchNormalization, Activation],to_file='figures/arch'+model+'.png')\n",
    "    l_mod.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638acea8-fe57-4cf1-9d3e-687a2bc8a575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Davenport-2021\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 46, 56, 10)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 46, 56, 16)        1456      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 46, 56, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 28, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " spatial_dropout2d (SpatialD  (None, 23, 28, 16)       0         \n",
      " ropout2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 23, 28, 16)        2320      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 23, 28, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " spatial_dropout2d_1 (Spatia  (None, 11, 14, 16)       0         \n",
      " lDropout2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2464)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                39440     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 168)               2856      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 12, 14, 1)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 24, 28, 16)       160       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 48, 56, 16)       2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 56, 1)         145       \n",
      "                                                                 \n",
      " cropping2d (Cropping2D)     (None, 46, 56, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,697\n",
      "Trainable params: 48,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l_mod[0].model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3bb7af-4aa9-412d-ab4c-b606cbd9d87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
