{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19f4c2-ab2d-4d19-8668-511e57a5ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.pipeline import Pipelines\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Conv2D, BatchNormalization,Flatten, MaxPooling2D\n",
    "from keras.layers import Conv2DTranspose,Concatenate,UpSampling2D,Cropping2D\n",
    "from keras.layers import Input, Lambda, Reshape, Dropout, Activation\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import datetime\n",
    "import math\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "# Dotenv\n",
    "from dotenv import dotenv_values\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_plot import *\n",
    "from utils.utils_unet import *\n",
    "from utils.utils_resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1e763-85f3-4bff-b525-cd15bb48569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "config = dotenv_values(\".env\")\n",
    "PATH_ERA5 = config['PATH_ERA5']\n",
    "PATH_EOBS = config['PATH_EOBS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64370f-444f-4549-9da9-44d40347516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "DATE_START = '1979-01-01'\n",
    "DATE_END = '2020-12-31'\n",
    "# train -test (80/20 of total yy), train-> split 80/20 for validation\n",
    "#YY_TRAIN = [1979, 2011] # 2005-2011 for validation\n",
    "#YY_VAL = [2005,2011]\n",
    "#YY_TEST = [2012, 2020]\n",
    "YY_TRAIN = [1979, 2015]\n",
    "YY_TEST = [2016, 2020]\n",
    "YY_VALID = 2005\n",
    "LEVELS = [500, 850, 1000]\n",
    "G = 9.80665 \n",
    "\n",
    "# define coordinates (for now use the same for the ppredictors and target)\n",
    "\n",
    "#LONS = [-25, 30]\n",
    "#LATS = [30, 75]\n",
    "# Note: for U-Net I have to select inputs/outputs as power of 2 for an easier implementation(maybe not neccesarily, but I couldn't find a better way)\n",
    "LONS = [-33, 30]\n",
    "LATS = [30, 77]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877276e-b76f-4055-bc40-c66c58c99957",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862df1a-95b2-447c-b7e7-60959398c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths for the variables used\n",
    "G = 9.80665\n",
    "l_paths = ['/precipitation/day_grid1/','/geopotential/grid1/','/temperature/grid1/','/relative_humidity/day_grid1/',\n",
    "              '/U_wind/day_grid1/','/V_wind/day_grid1/','/total_column_water/day_grid1/']\n",
    "v_vars = ['pr', 'z','t2m','rh','u850','v850','tpcw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c81c7-cd96-42ec-b509-860774d4fe2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_vars = load_data(v_vars, l_paths, G, PATH_ERA5, DATE_START, DATE_END, LONS, LATS, LEVELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe2185-58a9-4540-b1e9-c4d1a26f3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = list_vars[0]\n",
    "datasets = list_vars[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a50caf-3b4c-4bf7-a4fc-39921e07fb60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checking dimensions\n",
    "print('dimension of pr:',pr.dims)\n",
    "print('dimension of z',datasets[0].dims)\n",
    "print('dimension of t2m:',datasets[1].dims)\n",
    "print('dimension of rh:',datasets[2].dims)\n",
    "print('dimension of u:',datasets[3].dims)\n",
    "print('dimension of v:',datasets[4].dims)\n",
    "print('dimension of tw:',datasets[5].dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219acaac-8b61-4e8f-ac60-b92317669857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define precipitation extremes using the 95th\n",
    "th95 = 0.95 # can also be 0.99\n",
    "pr95 = precip_exceedance_xarray(pr, th95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e5e8d-d3e7-48cd-aab3-8d9f463d172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we need a dictionary for all the variables and levels we want to extract from the dataset\n",
    "#dic = OrderedDict({'z': 3, 'T2MMEAN':None, 'r':3})\n",
    "dic = {\n",
    "     'z': LEVELS,\n",
    "      'T2MMEAN': None,\n",
    "      'r': LEVELS,\n",
    "      'u': None,\n",
    "      'v': None,\n",
    "      'tcwv':None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207534dc-d8ce-4741-8747-9150eee2ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all have the same latitude order\n",
    "for idat in range(0, len(datasets)):\n",
    "    # Invert lat axis if needed\n",
    "    if datasets[idat].lat[0].values < datasets[idat].lat[1].values:\n",
    "        print('change lat order', idat)\n",
    "        datasets[idat] = datasets[idat].reindex(lat=list(reversed(datasets[idat].lat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004aa5e-eae6-403e-a0ef-177df0911fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e5453-c54f-4625-bf9d-0d652c2ad041",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64 # try increase, decrease it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36baa69d-9819-43e8-b849-8fee3db9ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test, then I will use DataGenerator class to get the validation\n",
    "ds_train = ds.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]),\n",
    "                             '{}-12-31'.format(YY_TRAIN[1])))\n",
    "ds_test = ds.sel(time=slice('{}-01-01'.format(YY_TEST[0]),\n",
    "                            '{}-12-31'.format(YY_TEST[1])))\n",
    "\n",
    "dy_train = pr95.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]),\n",
    "                             '{}-12-31'.format(YY_TRAIN[1])))\n",
    "dy_test = pr95.sel(time=slice('{}-01-01'.format(YY_TEST[0]),\n",
    "                             '{}-12-31'.format(YY_TEST[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61eb14-1ec0-4215-9769-ca0f5f90d80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a training and validation data generator. Use the train mean and std for validation as well.\n",
    "dg_train = MyDataGenerator(ds_train.sel(time=slice(f'{YY_TRAIN[0]}', f'{YY_VALID}')),\n",
    "                                dy_train.sel(time=slice(f'{YY_TRAIN[0]}', f'{YY_VALID}')), dic, batch_size= BATCH_SIZE, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba1225-50d2-4b2c-94c0-aee2135617c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation. Use the train mean and std for validation as well. And suffle\n",
    "dg_val = MyDataGenerator(ds_train.sel(time=slice(f'{YY_TRAIN[0]}', f'{YY_VALID}')),\n",
    "                                dy_train.sel(time=slice(f'{YY_TRAIN[0]}', f'{YY_VALID}')), dic, batch_size=BATCH_SIZE,  mean=dg_train.mean, std=dg_train.std, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56daff26-004f-4974-9519-b9f9040bacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now also a generator for testing. Impartant: Shuffle must be False!\n",
    "dg_test = MyDataGenerator(ds_test, dy_test, dic, batch_size=BATCH_SIZE, mean=dg_train.mean, std=dg_train.std, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7241f-172c-42df-86d2-7166a93a173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks\n",
    "n_figs = len(dg_train.data[0,0,0,:])\n",
    "ncols = 5\n",
    "nrows = -(-n_figs // ncols)\n",
    "fig, axes = plt.subplots(figsize=(24, 3*nrows), ncols=ncols, nrows=nrows)\n",
    "for i in range(n_figs):\n",
    "    i_row = i // ncols\n",
    "    i_col = i % ncols\n",
    "    im = axes[i_row, i_col].imshow(np.mean(dg_train.data[:,:,:,i], axis=0))\n",
    "    fig.colorbar(im, ax=axes[i_row, i_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81791f-56db-42b4-abc1-3bc31d37b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear session and set tf seed\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6cb2d-9d5d-4c26-b7da-7b26c3d7858e",
   "metadata": {},
   "source": [
    "# U-Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688a9a2-4c2a-410b-a5de-9c028cd03969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define args for the U-net model\n",
    "i_shape = dg_train.data.shape[1:]\n",
    "o_shape = dg_train.labels.shape[1:]\n",
    "\n",
    "print(f'X shape: {i_shape}')\n",
    "print(f'y shape: {o_shape}')\n",
    "output_channels = 1\n",
    "num_filters = 16\n",
    "use_batchnorm = True\n",
    "dropout = True\n",
    "lr = 0.0004\n",
    "optimizer = tf.optimizers.Adam(learning_rate = lr)\n",
    "EPOCHS = 20\n",
    "# Note: for U-net the input and output must be power of 2 ..\n",
    "# I will re-define the input for an easier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669bc696-be0d-49ee-9072-92f34618a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "    tf.metrics.Precision(class_id = 1, name='precision'),\n",
    "    tf.metrics.Recall(class_id = 1, name='recall')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec6a0b-ec68-467b-8892-124ce08d6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', classes = np.unique(dg_train.labels), y = np.array(dg_train.labels).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769830b0-2a49-46cc-9e10-d63effb5e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = weighted_binary_cross_entropy(weights = {0: weights[0].astype('float32'), 1: weights[1].astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9582e3-9d96-4d66-adef-1808692f7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mod = Unet2(i_shape, output_channels, num_filters, use_batchnorm, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab888b2-d982-4fc9-87ee-9be80e9b61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and compile\n",
    "um = u_mod.build_model()\n",
    "um.compile(optimizer =optimizer, loss = model_loss , metrics = METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9f2be-d1ee-44e6-9512-48d8c703454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_unet = um.fit(dg_train, epochs=EPOCHS, validation_data= dg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19bc99b-f69e-49cb-9ff0-c421b7f61dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 3)\n",
    "\n",
    "# For Sine Function\n",
    "pd.DataFrame(h_unet.history)[['loss','val_loss']].plot(figsize=(18,4), ax=axis[0], grid=True)\n",
    "pd.DataFrame(h_unet.history)[['precision','val_precision']].plot(figsize=(18,4), ax=axis[1],grid=True)\n",
    "pd.DataFrame(h_unet.history)[['recall','val_recall']].plot(figsize=(18,4), ax=axis[2],grid=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb06f3-67a2-4e56-976f-73588bfa2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred = um.predict(dg_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b8ce5-b781-4c99-b35d-d95f0bddf524",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= pred.reshape(pred.shape[0],pred.shape[1],pred.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2999f-2675-44dd-a190-5cd068b0bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_weighted_rmse(dg_test.labels,pred) #OK, I need to check this out.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b27541-30dd-46fd-ab18-0bb6a6def745",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe19777-9fa3-4af2-bfef-3c864b2b490f",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0c09e-f591-4dba-9744-3296b703af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_res = Adapted_resnet(i_shape) # not working..need to check if makes sense.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fc227-fc58-41c7-84b6-1e7c4ea0d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_res.compile(optimizer = optimizer, loss = model_loss , metrics = METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333121b7-0510-4235-b47a-7b00b3fbab67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_res = m_res.fit(dg_train, epochs=EPOCHS, validation_data= dg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce898f54-f091-44cc-b570-bc66f42a3433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
