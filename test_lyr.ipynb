{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f67371d-0f46-4aa5-96f2-cf9a680e8116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.pipeline import Pipelines\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "#from keras.layers.wrappers import TimeDistributed\n",
    "#from keras.layers import Dense,LSTM,Conv2D, BatchNormalization,Flatten, MaxPooling2D\n",
    "#from keras.layers import Conv2DTranspose,Concatenate,UpSampling2D,Cropping2D\n",
    "#from keras.layers import Input, Lambda, Reshape, Dropout, Activation\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Input, MaxPooling2D, Flatten, MaxPool2D, MaxPool3D, UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Flatten, Reshape, Cropping2D, Embedding, BatchNormalization,ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU, Activation, Input, add, multiply\n",
    "from tensorflow.keras.layers import concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import datetime\n",
    "import math\n",
    "import pathlib\n",
    "import hashlib\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "# Dotenv\n",
    "from dotenv import dotenv_values\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_plot import *\n",
    "from utils.utils_unet import *\n",
    "from utils.utils_resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd90a6d-0bd4-422e-8aa9-da95768c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "dg_test_X = np.array(xr.open_dataarray('tmp/data/dg_test_X.nc'))\n",
    "dg_test_Y = np.array(xr.open_dataarray('tmp/data/dg_test_Y.nc'))\n",
    "dg_test_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_test_Y_xtrm.nc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b232f9f-58cb-405b-a3bf-71794e5fc41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = xr.open_dataset('tmp/data/ds_test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca27c07-a2f1-4321-9741-a12a72604628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (46, 56, 10)\n",
      "y shape: (46, 56)\n"
     ]
    }
   ],
   "source": [
    "# Define args for the U-net model\n",
    "i_shape = dg_test_X.shape[1:]\n",
    "o_shape = (46,56)\n",
    "\n",
    "print(f'X shape: {i_shape}')\n",
    "print(f'y shape: {o_shape}')\n",
    "output_channels = 1\n",
    "num_filters = 32\n",
    "use_batchnorm = True\n",
    "dropout = True\n",
    "lr = 0.0004\n",
    "#optimizer = tf.optimizers.Adam(learning_rate = lr)\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c3ee24-5710-4621-9c06-9d75e3755dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_mod = ['unet']\n",
    "for imod in names_mod:\n",
    "    tmp_file = pathlib.Path(f'tmp/{imod}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57919c27-1455-4277-bf8a-846d788c37e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 08:36:05.010299: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-20 08:36:05.864570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10415 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "custom_objects = {\"weighted_cross_entropy_fn\": weighted_binary_cross_entropy}\n",
    "with keras.utils.custom_object_scope(custom_objects):\n",
    "                m = load_model(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a32a509-c4e7-4831-b84c-c4b170e3a8cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 46, 56, 10)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 48, 64, 10)  0           ['input_2[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 48, 64, 64)   5824        ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 48, 64, 64)   0           ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_4 (SpatialDr  (None, 48, 64, 64)  0           ['activation_16[0][0]']          \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 48, 64, 64)   36928       ['spatial_dropout2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 48, 64, 64)   0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 24, 32, 64)  0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 24, 32, 128)  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 24, 32, 128)  0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_5 (SpatialDr  (None, 24, 32, 128)  0          ['activation_18[0][0]']          \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 24, 32, 128)  147584      ['spatial_dropout2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 24, 32, 128)  0           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 12, 16, 128)  0          ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 12, 16, 256)  295168      ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 12, 16, 256)  0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_6 (SpatialDr  (None, 12, 16, 256)  0          ['activation_20[0][0]']          \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 12, 16, 256)  590080      ['spatial_dropout2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 12, 16, 256)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 6, 8, 256)   0           ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 6, 8, 512)    1180160     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 6, 8, 512)    0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_7 (SpatialDr  (None, 6, 8, 512)   0           ['activation_22[0][0]']          \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 8, 512)    2359808     ['spatial_dropout2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 6, 8, 512)    0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 3, 4, 512)   0           ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 3, 4, 1024)   4719616     ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 3, 4, 1024)  4096        ['conv2d_27[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 3, 4, 1024)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 3, 4, 1024)   9438208     ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 3, 4, 1024)  4096        ['conv2d_28[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 6, 8, 512)   2097664     ['batch_normalization_3[0][0]']  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " cropping2d_5 (Cropping2D)      (None, 6, 8, 512)    0           ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 6, 8, 1024)   0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'cropping2d_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 6, 8, 512)    4719104     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 6, 8, 512)    0           ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 6, 8, 512)    0           ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 6, 8, 512)    2359808     ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 6, 8, 512)    0           ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 12, 16, 256)  524544     ['activation_25[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " cropping2d_6 (Cropping2D)      (None, 12, 16, 256)  0           ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 12, 16, 512)  0           ['conv2d_transpose_5[0][0]',     \n",
      "                                                                  'cropping2d_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 12, 16, 256)  1179904     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 12, 16, 256)  0           ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 12, 16, 256)  0           ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 12, 16, 256)  590080      ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 12, 16, 256)  0           ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 24, 32, 128)  131200     ['activation_27[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " cropping2d_7 (Cropping2D)      (None, 24, 32, 128)  0           ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 24, 32, 256)  0           ['conv2d_transpose_6[0][0]',     \n",
      "                                                                  'cropping2d_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 24, 32, 128)  295040      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 24, 32, 128)  0           ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 24, 32, 128)  0           ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 24, 32, 128)  147584      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 24, 32, 128)  0           ['conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 48, 64, 64)  32832       ['activation_29[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " cropping2d_8 (Cropping2D)      (None, 48, 64, 64)   0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 48, 64, 128)  0           ['conv2d_transpose_7[0][0]',     \n",
      "                                                                  'cropping2d_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 48, 64, 64)   73792       ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 48, 64, 64)   0           ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 48, 64, 64)   0           ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 48, 64, 64)   36928       ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 48, 64, 64)   0           ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 48, 64, 1)    65          ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " cropping2d_9 (Cropping2D)      (None, 46, 56, 1)    0           ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,043,969\n",
      "Trainable params: 31,039,873\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8d11ae-9a6d-402d-af9f-d8657070f9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 08:36:26.628108: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = m.predict(dg_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f2dbf0-aa13-442e-abeb-171721454ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2192, 46, 56, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73b365f-ae3f-4dbf-8dac-ec4538cb168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(2192,46,56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "076faec2-69c2-4a85-b3db-ee5f6129d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.where(np.isnan(predictions[:,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13e1d28-750f-425d-bcb0-831a7ec1ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the visualization model\n",
    "#layer_names = [layer.name for layer in m.layers]\n",
    "layer_outputs = [layer.output for layer in m.layers]\n",
    "feature_map_model = tf.keras.models.Model(inputs=m.input,\n",
    "                                          outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885b1897-fd10-4c7e-818d-10048df0e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get weights\n",
    "train_weights = m.trainable_weights\n",
    "raw_weigths = m.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6abdb2b-a2fe-4f24-a5e8-4c6b9f780275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract activation layers\n",
    "activations = [layer.output for layer in m.layers]\n",
    "activations = activations[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8820a3a-7402-43c3-b396-7e7f6f1d31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer names and outputs\n",
    "#layer_names = [layer.name for layer in m.layers]\n",
    "layer_names = [layer.name for layer in m.layers if 'dropout' not in layer.name]\n",
    "layer_names = layer_names[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fac3c8-9c6a-4206-a470-dc6b77b2e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(model):\n",
    "    names, activations, weights, strids = [], [], [], []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        name = layer.name if layer.name != 'predictions' else 'fc_out'\n",
    "        names.append(name)\n",
    "        activations.append(layer.output)\n",
    "        weights.append(layer.get_weights())\n",
    "        if 'conv' in name: #conv 일때 stride 값 저장\n",
    "            strids.append(layer.strides)#s[0])\n",
    "        else:\n",
    "            strids.append([])\n",
    "    return names, activations, weights, strids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26ec4f95-40e9-4d7c-9e61-ad67ce49b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2\n",
    "epsilon=1e-7\n",
    "\n",
    "names, activations, weights, strides = get_model_params(m)\n",
    "num_layers = len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ecde78-529d-46e2-bdb3-ca02b37a4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2\n",
    "beta = 1 - alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3b2bf0-3226-4886-972c-b38e51aac7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=m.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c576a609-02d4-40af-b0ae-5f8a6002132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.relevance = self.compute_relevances()\n",
    "#        self.lrp_runner = tf.keras.backend.function(inputs=[self.model.input, ], outputs=[self.relevance, ])\n",
    "def backprop_fc( w, b, a, r):\n",
    "    w_p = tf.maximum(w, 0.)\n",
    "    b_p = tf.maximum(b, 0.)\n",
    "    z_p = tf.matmul(a, w_p) + b_p + epsilon\n",
    "    \n",
    "    s_p = r / z_p\n",
    "    c_p = tf.matmul(s_p, tf.transpose(w_p))\n",
    "\n",
    "    w_n = tf.minimum(w, 0.)\n",
    "    b_n = tf.minimum(b, 0.)\n",
    "    z_n = tf.matmul(a, w_n) + b_n - epsilon\n",
    "    \n",
    "    #z_n_crop = crop_output(r, z_n)\n",
    "    #s_n = r / z_n_crop\n",
    "    #c_n = tf.matmul(s_n, tf.transpose(w_n))\n",
    "\n",
    "    return a * c_p#(self.alpha * c_p + self.beta * c_n)\n",
    "\n",
    "def backprop_flatten( a, r):\n",
    "    shape = a.get_shape().as_list()\n",
    "    shape[0] = -1\n",
    "    return tf.reshape(r, shape)\n",
    "\n",
    "def backprop_max_pool2d(a, r, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1)):\n",
    "    #z = tf.nn.pool2d(a, pool_size=ksize[1:-1], strides=strides[1:-1], padding='VALID', pool_mode='max')\n",
    "    z = tf.nn.max_pool(a, ksize[1:-1], strides=strides[1:-1], padding='SAME') + epsilon\n",
    "\n",
    "    z_p = tf.maximum(z, 0.) + epsilon\n",
    "    s_p = r / z_p\n",
    "    c_p = gen_nn_ops.max_pool_grad_v2(a, z_p, s_p, ksize, strides, padding='SAME')\n",
    "\n",
    "    z_n = tf.minimum(z, 0.) - epsilon\n",
    "    s_n = r / z_n\n",
    "    c_n = gen_nn_ops.max_pool_grad_v2(a, z_n, s_n, ksize, strides, padding='SAME')\n",
    "\n",
    "    return a * c_p #(self.alpha * c_p + self.beta * c_n)\n",
    "\n",
    "def backprop_conv2d( w, b, a, r, strides=(1, 1, 1, 1)):\n",
    "    w_p = tf.maximum(w, 0.)\n",
    "    b_p = tf.maximum(b, 0.)\n",
    "    z_p = tf.nn.conv2d(a, w_p, strides=strides, padding='SAME') + b_p + epsilon\n",
    "    \n",
    " \n",
    "    if (r.shape[1] > z_p.shape[1]):\n",
    "        r_p_crop = crop_output(z_p, r)\n",
    "        s_p = r_p_crop / z_p\n",
    "    else:\n",
    "        z_p_crop = crop_output(r, z_p)\n",
    "        s_p = r / z_p_crop\n",
    "        \n",
    "    #elif(r.shape[1] < z_p.shape[1]):\n",
    "    #    z_p_crop = crop_output(r, z_p)\n",
    "    #    s_p = r / z_p_crop\n",
    "        #s_p = r / z_p\n",
    "        \n",
    "    \n",
    "    c_p = tf.compat.v1.nn.conv2d_backprop_input(tf.shape(a), w_p, s_p, strides, padding='SAME')\n",
    "\n",
    "    w_n = tf.minimum(w, 0.)\n",
    "    b_n = tf.minimum(b, 0.)\n",
    "    z_n = tf.nn.conv2d(a, w_n, strides=strides, padding='SAME') + b_n - epsilon\n",
    "    \n",
    "    if (r.shape[1] > z_n.shape[1]):\n",
    "        r_n_crop = crop_output(z_n, r)\n",
    "        s_n = r_n_crop / z_n\n",
    "    else:\n",
    "        z_n_crop = crop_output(r, z_n)\n",
    "        s_n = r / z_n_crop\n",
    "\n",
    "    #s_n = r / z_n\n",
    "    c_n = tf.compat.v1.nn.conv2d_backprop_input(tf.shape(a), w_n, s_n, strides, padding='SAME')\n",
    "    \n",
    "    return a * c_p #(self.alpha * c_p + self.beta * c_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87871f9b-6315-44e1-b2ba-39d1d459a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution \n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "066b37f8-c644-4d2a-9ad1-74b37a97269f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "cropping2d_9\n",
      "r\n",
      "62\n",
      "conv2d_37\n",
      "61\n",
      "activation_31\n",
      "r\n",
      "60\n",
      "conv2d_36\n",
      "59\n",
      "dropout_9\n",
      "r\n",
      "58\n",
      "activation_30\n",
      "r\n",
      "57\n",
      "conv2d_35\n",
      "56\n",
      "concatenate_7\n",
      "r\n",
      "55\n",
      "cropping2d_8\n",
      "r\n",
      "54\n",
      "conv2d_transpose_7\n",
      "r\n",
      "53\n",
      "activation_29\n",
      "r\n",
      "52\n",
      "conv2d_34\n",
      "51\n",
      "dropout_8\n",
      "r\n",
      "50\n",
      "activation_28\n",
      "r\n",
      "49\n",
      "conv2d_33\n",
      "48\n",
      "concatenate_6\n",
      "r\n",
      "47\n",
      "cropping2d_7\n",
      "r\n",
      "46\n",
      "conv2d_transpose_6\n",
      "r\n",
      "45\n",
      "activation_27\n",
      "r\n",
      "44\n",
      "conv2d_32\n",
      "43\n",
      "dropout_7\n",
      "r\n",
      "42\n",
      "activation_26\n",
      "r\n",
      "41\n",
      "conv2d_31\n",
      "40\n",
      "concatenate_5\n",
      "r\n",
      "39\n",
      "cropping2d_6\n",
      "r\n",
      "38\n",
      "conv2d_transpose_5\n",
      "r\n",
      "37\n",
      "activation_25\n",
      "r\n",
      "36\n",
      "conv2d_30\n",
      "35\n",
      "dropout_6\n",
      "r\n",
      "34\n",
      "activation_24\n",
      "r\n",
      "33\n",
      "conv2d_29\n",
      "32\n",
      "concatenate_4\n",
      "r\n",
      "31\n",
      "cropping2d_5\n",
      "r\n",
      "30\n",
      "conv2d_transpose_4\n",
      "r\n",
      "29\n",
      "batch_normalization_3\n",
      "r\n",
      "28\n",
      "conv2d_28\n",
      "27\n",
      "dropout_5\n",
      "r\n",
      "26\n",
      "batch_normalization_2\n",
      "r\n",
      "25\n",
      "conv2d_27\n",
      "24\n",
      "max_pooling2d_7\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 6, 8, 512), dtype=tf.float32, name=None), name='activation_23/Relu:0', description=\"created by layer 'activation_23'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/26028753/ipykernel_19840/3406091720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'pool'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop_max_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'conv2d'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop_conv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/26028753/ipykernel_19840/1927678409.py\u001b[0m in \u001b[0;36mbackprop_max_pool2d\u001b[0;34m(a, r, ksize, strides)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mz_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0ms_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mz_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mc_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool_grad_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mz_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool_grad_v2\u001b[0;34m(orig_input, orig_output, grad, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   6251\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6252\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6253\u001b[0;31m       return max_pool_grad_v2_eager_fallback(\n\u001b[0m\u001b[1;32m   6254\u001b[0m           \u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6255\u001b[0m           data_format=data_format, name=name, ctx=_ctx)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool_grad_v2_eager_fallback\u001b[0;34m(orig_input, orig_output, grad, ksize, strides, padding, data_format, name, ctx)\u001b[0m\n\u001b[1;32m   6283\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NHWC\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6284\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6285\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_inputs_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6286\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inputs_T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6287\u001b[0m   \u001b[0mksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                          as_ref=False):\n\u001b[1;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;34mf'You are passing {self}, an intermediate Keras symbolic input/output, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;34m'to a TF API that does not allow registering custom dispatchers, such '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 6, 8, 512), dtype=tf.float32, name=None), name='activation_23/Relu:0', description=\"created by layer 'activation_23'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "r = m.output\n",
    "for i in range(num_layers - 2, -1, -1):\n",
    "    print(i)\n",
    "    print(names[i+1])\n",
    "    # note: max_pooling is not working, need to figure this out\n",
    "    if 'dropout' in names[i + 1] or 'normalization' in names[i+1] or 'cropping' in names[i+1] or 'concatenate' in names[i+1] or 'activation' in names[i+1] or 'conv2d_transpose' in names[i+1] or 'zero_padding2d' in names[i+1]  :\n",
    "        print('r')\n",
    "        r = r\n",
    "    elif 'dense' in names[i + 1]:\n",
    "        r = backprop_fc(weights[i + 1][0], weights[i + 1][1], activations[i], r)\n",
    "    elif 'flatten' in names[i + 1]:\n",
    "        r = backprop_flatten(activations[i], r)\n",
    "    elif 'pool' in names[i + 1]:\n",
    "        r = backprop_max_pool2d(activations[i], r)\n",
    "    elif 'conv2d' in names[i + 1]:\n",
    "        r = backprop_conv2d(weights[i + 1][0], weights[i + 1][1], activations[i], r)\n",
    "    #elif 'conv2d_transpose' in names[i + 1]:\n",
    "    #    r = backprop_conv2d(weights[i + 1][0], weights[i + 1][1], activations[i], r, strides=strides[i+1])\n",
    "    elif 'conv1d' in names[i + 1]:\n",
    "        r = backprop_conv1d(weights[i + 1][0], weights[i + 1][1], activations[i], r, strides=strides[i+1])\n",
    "  \n",
    "    else:\n",
    "        raise 'Layer not recognized!'\n",
    "        sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03082cf9-d8e3-42eb-a681-ce51ea2fdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=activations[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "939df887-a091-4fd3-a8a0-848325a0c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksize=(1, 2, 2, 1)\n",
    "strides=(1, 2, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf5f8d4-7c25-4592-aa17-271f6034ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.nn.max_pool(a, ksize[1:-1], strides=strides[1:-1], padding='SAME') + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fbccbf6-8090-4e12-80ff-a23b0fb6bb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3, 4, 512) dtype=float32 (created by layer 'tf.__operators__.add_35')>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13b7cb40-5c8c-455d-95ad-ced11f2b960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_p = tf.maximum(z, 0.) + epsilon\n",
    "s_p = r / z_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2723e12-fb83-4c93-8322-26c87e0b4deb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 6, 8, 512), dtype=tf.float32, name=None), name='activation_23/Relu:0', description=\"created by layer 'activation_23'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/26028753/ipykernel_19840/2285745219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool_grad_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool_grad_v2\u001b[0;34m(orig_input, orig_output, grad, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   6251\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6252\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6253\u001b[0;31m       return max_pool_grad_v2_eager_fallback(\n\u001b[0m\u001b[1;32m   6254\u001b[0m           \u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6255\u001b[0m           data_format=data_format, name=name, ctx=_ctx)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool_grad_v2_eager_fallback\u001b[0;34m(orig_input, orig_output, grad, ksize, strides, padding, data_format, name, ctx)\u001b[0m\n\u001b[1;32m   6283\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NHWC\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6284\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6285\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_inputs_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6286\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inputs_T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6287\u001b[0m   \u001b[0mksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                          as_ref=False):\n\u001b[1;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;34mf'You are passing {self}, an intermediate Keras symbolic input/output, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;34m'to a TF API that does not allow registering custom dispatchers, such '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 6, 8, 512), dtype=tf.float32, name=None), name='activation_23/Relu:0', description=\"created by layer 'activation_23'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "c_p = gen_nn_ops.max_pool_grad_v2(a, z_p, s_p, ksize, strides, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1ac05-1e42-40f5-9286-86c11fc22b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c41174f5-b88e-4436-86dd-9aa90c86e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dg_test_X[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd701d18-f0d7-4402-9945-383522bacb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = tf.expand_dims(img, axis=0)\n",
    "image = img[None,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cdc2e239-0f56-425b-8776-1671a66aa179",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = K.function(inputs=m.input, outputs=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6494af2-f5f2-4edd-aad2-91437e07c62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 48, 64, 10) dtype=float32 (created by layer 'tf.math.multiply_75')>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "411c15f1-d81f-46e0-b257-66c48fdd85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp_runner = K.function(inputs=[m.input, ], outputs=[r, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "249fbedc-051f-4797-8f2e-a12fa4ebf7a1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 15:28:37.094069: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_grad_input_ops.cc:96 : INVALID_ARGUMENT: Conv2DSlowBackpropInput: Size of out_backprop doesn't match computed: actual = 46, computed = 48 spatial_dim: 1 input: 48 filter: 1 output: 46 stride: 1 dilation: 1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"tf.compat.v1.nn.conv2d_backprop_input_116\" (type TFOpLambda).\n\nConv2DSlowBackpropInput: Size of out_backprop doesn't match computed: actual = 46, computed = 48 spatial_dim: 1 input: 48 filter: 1 output: 46 stride: 1 dilation: 1 [Op:Conv2DBackpropInput]\n\nCall arguments received:\n  • input_sizes=tf.Tensor(shape=(4,), dtype=int32)\n  • filter=tf.Tensor(shape=(1, 1, 64, 1), dtype=float32)\n  • out_backprop=tf.Tensor(shape=(1, 46, 56, 1), dtype=float32)\n  • strides=('1', '1', '1', '1')\n  • padding='SAME'\n  • use_cudnn_on_gpu=True\n  • data_format=NHWC\n  • dilations=[1, 1, 1, 1]\n  • name=None\n  • filters=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/25959125/ipykernel_10580/4097419986.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrp_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4320\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4322\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4323\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4324\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"tf.compat.v1.nn.conv2d_backprop_input_116\" (type TFOpLambda).\n\nConv2DSlowBackpropInput: Size of out_backprop doesn't match computed: actual = 46, computed = 48 spatial_dim: 1 input: 48 filter: 1 output: 46 stride: 1 dilation: 1 [Op:Conv2DBackpropInput]\n\nCall arguments received:\n  • input_sizes=tf.Tensor(shape=(4,), dtype=int32)\n  • filter=tf.Tensor(shape=(1, 1, 64, 1), dtype=float32)\n  • out_backprop=tf.Tensor(shape=(1, 46, 56, 1), dtype=float32)\n  • strides=('1', '1', '1', '1')\n  • padding='SAME'\n  • use_cudnn_on_gpu=True\n  • data_format=NHWC\n  • dilations=[1, 1, 1, 1]\n  • name=None\n  • filters=None"
     ]
    }
   ],
   "source": [
    "lrp_runner(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12777bf-db94-467f-8d86-18abf1d5296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(image):\n",
    "        \"\"\"Computes feature relevance scores for single image\n",
    "        :param image: ndarray of shape (W, H, C)\n",
    "        :return: features_relevance_scores: ndarray of same size as input image\n",
    "        \"\"\"\n",
    "        image = preprocess_input(image)\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        relevance_scores = self.f(inputs=image)\n",
    "        relevance_scores = self.postprocess(relevance_scores)\n",
    "        return np.squeeze(relevance_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4348db-794c-48df-97ac-a32f87cf410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(image, cmap_type='rainbow', reduce_op='sum', reduce_axis=-1, **kwargs):\n",
    "    cmap = get_cmap(cmap_type)\n",
    "    shape = list(image.shape)\n",
    "    reduced_image = reduce_channels(image, axis=reduce_axis, op=reduce_op)\n",
    "    projected_image = project_image(reduced_image, **kwargs)\n",
    "    heatmap = cmap(projected_image.flatten())[:, :3].T\n",
    "    heatmap = heatmap.T\n",
    "    shape[reduce_axis] = 3\n",
    "    return heatmap.reshape(shape)\n",
    "\n",
    "def get_heatmaps(gammas, cmap_type='rainbow', **kwargs):\n",
    "    heatmaps = [heatmap(g, cmap_type=cmap_type, **kwargs) for g in gammas]\n",
    "    return heatmaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
