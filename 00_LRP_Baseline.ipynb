{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d545b75d",
   "metadata": {},
   "source": [
    "# LRP baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1427bd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import pathlib\n",
    "import hashlib\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Dotenv\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_resnet import *\n",
    "from utils.utils_plot import *\n",
    "from utils.DNN_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a538e73-d554-464b-8b56-9f2690110750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "conf = yaml.safe_load(open(\"config.yaml\"))\n",
    "PRECIP_XTRM = 0.95 # Percentile (threshold) for the extremes\n",
    "PRECIP_DATA = 'ERA5-low' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e326642-b002-4e29-a8be-3740c2b2a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: [46, 56, 31]\n",
      "y shape: [46, 56, 1]\n"
     ]
    }
   ],
   "source": [
    "i_shape = conf['i_shape']\n",
    "o_shape = conf['o_shape']\n",
    "\n",
    "print(f'X shape: {i_shape}')\n",
    "print(f'y shape: {o_shape}')\n",
    "output_channels = conf['output_channels']\n",
    "num_filters = conf['num_filters']\n",
    "use_batchnorm = conf['use_batchnorm']\n",
    "dropout = conf['dropout']\n",
    "lr = conf['lr']\n",
    "\n",
    "name_model = conf['model']\n",
    "output_scaling = 1\n",
    "output_crop = None\n",
    "\n",
    "\n",
    "# load coordinates\n",
    "lons_x = np.load('tmp/data/lons_y.npy')\n",
    "lats_y = np.load('tmp/data/lats_y.npy')\n",
    "\n",
    "# load precip\n",
    "if PRECIP_XTRM == 0.95:\n",
    "    pr_xtrm = np.load('tmp/data/pr_xtrm_95.npy')\n",
    "elif PRECIP_XTRM == 0.99:\n",
    "    pr_xtrm = np.load('tmp/data/pr_xtrm_99.npy')\n",
    "#pr_xtrm = np.load('tmp/data/pr_xtrm_99.npy')\n",
    "# create a time array\n",
    "times = np.arange(np.datetime64('1979-01-01'), np.datetime64('2006-01-01')) #until validation period\n",
    "times = pd.to_datetime(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e21f09-2b6a-488a-a2fb-bb9a7d0c336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing data\n",
    "dg_train_X = np.array(xr.open_dataarray('tmp/data/dg_train_X.nc'))\n",
    "dg_train_Y = np.array(xr.open_dataarray('tmp/data/dg_train_Y.nc'))\n",
    "\n",
    "dg_valid_X = np.array(xr.open_dataarray('tmp/data/dg_valid_X.nc'))\n",
    "dg_valid_Y = np.array(xr.open_dataarray('tmp/data/dg_valid_Y.nc'))\n",
    "\n",
    "\n",
    "test_times = np.arange(np.datetime64('2016-01-01'), np.datetime64('2022-01-01')) #until validation period\n",
    "test_times = pd.to_datetime(test_times)\n",
    "dg_test_X = np.array(xr.open_dataarray('tmp/data/dg_test_X.nc'))\n",
    "dg_test_Y = np.array(xr.open_dataarray('tmp/data/dg_test_Y.nc'))\n",
    "\n",
    "# Open files for extremes\n",
    "if PRECIP_XTRM == 0.95:\n",
    "    dg_train_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_train_Y_xtrm0.95th.nc'))\n",
    "    dg_valid_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_valid_Y_xtrm0.95th.nc')) \n",
    "    dg_test_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_test_Y_xtrm0.95th.nc'))\n",
    "elif PRECIP_XTRM == 0.99:\n",
    "    dg_train_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_train_Y_xtrm0.99th.nc'))\n",
    "    dg_valid_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_valid_Y_xtrm0.99th.nc')) \n",
    "    dg_test_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_test_Y_xtrm0.99th.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53125a84-f898-4094-87de-af796bd97c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pass zeros through the network to asses the baseline\n",
    "dg_train_X_null = np.zeros(dg_train_X.shape)\n",
    "dg_valid_X_null = np.zeros(dg_valid_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc1d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for the weighted binary crossentropy:\n",
      "Classes: [0 1], weights: [0.52634048 9.99109415]\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "LR_METHOD = 'Constant'  # Cyclical, CosineDecay, Constant\n",
    "                                            \n",
    "\n",
    "\n",
    "# Compute weights for the weighted binary crossentropy\n",
    "weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(pr_xtrm),\n",
    "    y=pr_xtrm.flatten()\n",
    ")\n",
    "\n",
    "print('Weights for the weighted binary crossentropy:')\n",
    "print(f'Classes: {np.unique(pr_xtrm)}, weights: {weights}')\n",
    "\n",
    "# Create loss function for the extremes\n",
    "xtrm_loss = weighted_binary_cross_entropy(\n",
    "    weights={0: weights[0].astype('float32'), 1: weights[1].astype('float32')})\n",
    "\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "EPOCHS = 10\n",
    "LR_METHOD = 'Constant'  # Cyclical, CosineDecay, Constant\n",
    "    \n",
    "# Early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,\n",
    "                                            restore_best_weights=True)\n",
    "                                            \n",
    "# Default model options\n",
    "opt_model = {'latent_dim': 128,\n",
    "             'dropout_rate': 0.2}\n",
    "\n",
    "# Default training options\n",
    "opt_training = {'epochs': EPOCHS,\n",
    "                'callbacks': [callback]}\n",
    "\n",
    "# Default optimizer options\n",
    "opt_optimizer = {'lr_method': 'Constant',\n",
    "                 'lr': 0.0004,\n",
    "                 'init_lr': 0.01}\n",
    "\n",
    "models_unets = {\n",
    "          'UNET1': {'model': 'Unet', 'run': False,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 1, 'use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET2': {'model': 'Unet', 'run': False,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 2, 'use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET3': {'model': 'Unet', 'run': False,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 3, 'use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET4': {'model': 'Unet', 'run': True,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 4, 'use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d0b2d7-f43a-4baa-b7f9-b3e6afeab04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models_unets\n",
    "\n",
    "train_for_prec = True\n",
    "train_for_xtrm = False\n",
    "history_log_level = 1\n",
    "\n",
    "\n",
    "# define loss function\n",
    "loss_regression = 'mse'\n",
    "\n",
    "models_prec = []\n",
    "models_xtrm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4baf76cc-83a3-4a68-a204-f7b9e7b622b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 13:40:06.689475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 13:40:07.335570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 31418369\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 13:40:13.849846: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 31s 80ms/step - loss: 7.3760 - mse: 7.3760 - val_loss: 5.3387 - val_mse: 5.3387\n",
      "Epoch 2/10\n",
      "309/309 [==============================] - 21s 67ms/step - loss: 5.1582 - mse: 5.1582 - val_loss: 4.6120 - val_mse: 4.6120\n",
      "Epoch 3/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 4.5270 - mse: 4.5270 - val_loss: 4.1004 - val_mse: 4.1004\n",
      "Epoch 4/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 4.1863 - mse: 4.1863 - val_loss: 4.0943 - val_mse: 4.0943\n",
      "Epoch 5/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 3.8839 - mse: 3.8839 - val_loss: 3.5628 - val_mse: 3.5628\n",
      "Epoch 6/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 3.7351 - mse: 3.7351 - val_loss: 3.4349 - val_mse: 3.4349\n",
      "Epoch 7/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 3.5751 - mse: 3.5751 - val_loss: 3.3599 - val_mse: 3.3599\n",
      "Epoch 8/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 3.4799 - mse: 3.4799 - val_loss: 3.9938 - val_mse: 3.9938\n",
      "Epoch 9/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 3.3488 - mse: 3.3488 - val_loss: 3.5554 - val_mse: 3.5554\n",
      "Epoch 10/10\n",
      "309/309 [==============================] - 21s 68ms/step - loss: 3.2573 - mse: 3.2573 - val_loss: 3.2338 - val_mse: 3.2338\n",
      "Saving weights\n"
     ]
    }
   ],
   "source": [
    "if train_for_prec:\n",
    "        \n",
    "    for m_id in models:\n",
    "        # Clear session and set tf seed\n",
    "        keras.backend.clear_session()\n",
    "        tf.random.set_seed(42)\n",
    "        \n",
    "        if not models[m_id]['run']:\n",
    "            continue\n",
    "\n",
    "        # Extract model name and options\n",
    "        model = models[m_id]['model']\n",
    "        opt_model_i = models[m_id]['opt_model']\n",
    "        opt_optimizer_i = models[m_id]['opt_optimizer']\n",
    "        opt_model_new = opt_model.copy()\n",
    "        opt_model_new.update(opt_model_i)\n",
    "        opt_optimizer_new = opt_optimizer.copy()\n",
    "        opt_optimizer_new.update(opt_optimizer_i)\n",
    "      \n",
    "        \n",
    "        optimizer = initiate_optimizer(**opt_optimizer_new)\n",
    "\n",
    "\n",
    "        # Create the model and compile\n",
    "        # Update: to apply lrp the last activation function is recommended to be linear (see innvestigate)\n",
    "        m = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=False, for_lrp = True, **opt_model_new)\n",
    "        # Warning: When using regularizers, the loss function is the entire loss, ie (loss metrics) + (regularization term)!\n",
    "        # But the loss displayed as part of the metrics, is only the loss metric. The regularization term is not added there. -> can be different!!\n",
    "        loss_fct = 'mse'\n",
    "        if loss_regression == 'mse_nans':\n",
    "            loss_fct = MeanSquaredErrorNans()\n",
    "        \n",
    "        m.model.compile(\n",
    "                loss=loss_fct, \n",
    "                metrics=[loss_fct], \n",
    "                optimizer=optimizer\n",
    "            )\n",
    "        print(f'Number of parameters: {m.model.count_params()}')\n",
    "\n",
    "        # Train with the NULL datasets to assess the baseline\n",
    "        hist = m.model.fit(dg_train_X_null, dg_train_Y, validation_data=(dg_valid_X_null, dg_valid_Y), **opt_training)\n",
    "        \n",
    "        # Saving the model\n",
    "        print('Saving weights')\n",
    "        m.model.save_weights(f'tmp/Keras_Baseline/null_input/{PRECIP_DATA}_{PRECIP_XTRM}_{m_id}.h5')\n",
    "        \n",
    "        \n",
    "if train_for_xtrm:\n",
    "\n",
    "    for m_id in models:\n",
    "        # Clear session and set tf seed\n",
    "        keras.backend.clear_session()\n",
    "        tf.random.set_seed(42)\n",
    "\n",
    "        if not models[m_id]['run']:\n",
    "            continue\n",
    "        \n",
    "        # Extract model name and options\n",
    "        model = models[m_id]['model']\n",
    "        opt_model_i = models[m_id]['opt_model']\n",
    "        opt_optimizer_i = models[m_id]['opt_optimizer']\n",
    "        opt_model_new = opt_model.copy()\n",
    "        opt_model_new.update(opt_model_i)\n",
    "        opt_optimizer_new = opt_optimizer.copy()\n",
    "        opt_optimizer_new.update(opt_optimizer_i)\n",
    "        print(f'Running: {m_id} - {model} - {opt_model_i} - {opt_optimizer_i}')\n",
    "        \n",
    "        \n",
    "        optimizer = initiate_optimizer(**opt_optimizer_new)\n",
    "        \n",
    "     \n",
    "        # Create the model and compile\n",
    "        m = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=True, for_lrp = True, **opt_model_new)\n",
    "        m.model.compile(\n",
    "                loss=xtrm_loss,\n",
    "                optimizer=optimizer\n",
    "        )\n",
    "        print(f'Number of parameters: {m.model.count_params()}')\n",
    "\n",
    "        # Train\n",
    "        hist = m.model.fit(dg_train_X_null, dg_train_Y, validation_data=(dg_valid_X_null, dg_valid_Y), verbose=history_log_level, **opt_training)\n",
    "            \n",
    "           \n",
    "        # Saving the model\n",
    "        m.model.save_weights(f'tmp/Keras_Baseline/null_input/{PRECIP_DATA}_{PRECIP_XTRM}_{m_id}_xtrm.h5')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b89c68-55db-4778-9fe6-88eb9abca466",
   "metadata": {},
   "source": [
    "### Additional test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd109fd-c561-44ac-8fc4-f1277f8844c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############LRP ###########\n",
    "EPOCHS = 10\n",
    "m_id = 'UNET4'\n",
    "model = models[m_id]['model']\n",
    "opt_model_i = models[m_id]['opt_model']\n",
    "opt_optimizer_i = models[m_id]['opt_optimizer']\n",
    "\n",
    "opt_model_new = opt_model.copy()\n",
    "opt_model_new.update(opt_model_i)\n",
    "opt_optimizer_new = opt_optimizer.copy()\n",
    "opt_optimizer_new.update(opt_optimizer_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bdd258e-0af1-4c74-8b41-d2ce63f4e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extremes\n",
    "m = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=True,**opt_model_new)\n",
    "\n",
    "# compile \n",
    "m.model.compile(loss=keras.losses.categorical_crossentropy, ## instead of CategoricalCrossentropy\n",
    "                  optimizer='adam', ## lr instead of learning_rate\n",
    "                  metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1183a095-6d46-4f43-a0e2-0618e2917280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:26:04.838321: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8f07c7a60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train \n",
    "m.model.fit(dg_train_X, dg_train_Y_xtrm, validation_data=(dg_valid_X, dg_valid_Y_xtrm), \n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a495bdc0-fc28-4433-9b28-4e9627a67d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model.save_weights('tmp/tmp_weights_DNN/UNET4_0.95th_xtrm_trained_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "451288bf-8449-4d11-a2c3-de7fb90caa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:34:43.495378: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-03 09:34:44.155315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Not extremes\n",
    "m_pr = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=False,**opt_model_new)\n",
    "\n",
    "# compile \n",
    "m_pr.model.compile( loss='mse',  metrics=['mse'],  optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eabaeff-d15e-4a8a-ab16-1d59e2fcec9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:35:06.262970: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 29s 140ms/step - loss: 6.9837 - mse: 6.9837 - val_loss: 5.7747 - val_mse: 5.7747\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 18s 113ms/step - loss: 4.8747 - mse: 4.8747 - val_loss: 4.5110 - val_mse: 4.5110\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 18s 114ms/step - loss: 4.2975 - mse: 4.2975 - val_loss: 4.0320 - val_mse: 4.0320\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 18s 114ms/step - loss: 3.9479 - mse: 3.9479 - val_loss: 4.2180 - val_mse: 4.2180\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 18s 115ms/step - loss: 3.7540 - mse: 3.7540 - val_loss: 3.7675 - val_mse: 3.7675\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 18s 115ms/step - loss: 3.5726 - mse: 3.5726 - val_loss: 3.4176 - val_mse: 3.4176\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 18s 114ms/step - loss: 3.4416 - mse: 3.4416 - val_loss: 4.0747 - val_mse: 4.0747\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 18s 115ms/step - loss: 3.3516 - mse: 3.3515 - val_loss: 3.2536 - val_mse: 3.2536\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 18s 114ms/step - loss: 3.2424 - mse: 3.2424 - val_loss: 3.0796 - val_mse: 3.0796\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 18s 115ms/step - loss: 3.1577 - mse: 3.1577 - val_loss: 3.1776 - val_mse: 3.1776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94e65b6a30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pr.model.fit(dg_train_X, dg_train_Y, validation_data=(dg_valid_X, dg_valid_Y), \n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c4b6c7-1140-400f-864d-f052ddf3770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pr.model.save_weights('tmp/tmp_weights_DNN/UNET4_pr_trained_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de44f8d-c07b-420a-afd2-c3962afe77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model for the baseline- pasing zero through the network, using linear activation function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24de41ce-9667-45fa-a750-decf5f57762b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:41:03.977862: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-03 09:41:04.641172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:41:12.242114: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 29s 142ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 17s 112ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 17s 112ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 17s 113ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 17s 113ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 17s 113ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 18s 113ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 18s 114ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 18s 113ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 18s 113ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70c0025c40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_extr_null = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=True, for_lrp=True, **opt_model_new)\n",
    "\n",
    "# compile \n",
    "m_extr_null.model.compile(loss=keras.losses.categorical_crossentropy, ## instead of CategoricalCrossentropy\n",
    "                  optimizer='adam', ## lr instead of learning_rate\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "m_extr_null.model.fit(dg_train_X_null, dg_train_Y_xtrm, validation_data=(dg_valid_X_null, dg_valid_Y_xtrm), \n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0ee8b2d-142d-457e-8506-c0c7a432fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_extr_null.model.save_weights('tmp/tmp_weights_DNN/UNET4_prxtrm_NULL_linear_trained_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "517c6be9-3a0d-44eb-b930-13691cfff101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:48:14.644171: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-03 09:48:15.308870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 09:48:22.814061: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 29s 141ms/step - loss: 22.1827 - mse: 22.1827 - val_loss: 23.0957 - val_mse: 23.0957\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 17s 112ms/step - loss: 21.5591 - mse: 21.5590 - val_loss: 22.4856 - val_mse: 22.4856\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 17s 112ms/step - loss: 20.9999 - mse: 20.9999 - val_loss: 21.9388 - val_mse: 21.9388\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 17s 112ms/step - loss: 20.5009 - mse: 20.5009 - val_loss: 21.4504 - val_mse: 21.4504\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 17s 112ms/step - loss: 20.0577 - mse: 20.0577 - val_loss: 21.0158 - val_mse: 21.0158\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 19.6651 - mse: 19.6651 - val_loss: 20.6308 - val_mse: 20.6308\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 19.3203 - mse: 19.3203 - val_loss: 20.2928 - val_mse: 20.2928\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 17s 112ms/step - loss: 19.0184 - mse: 19.0184 - val_loss: 19.9959 - val_mse: 19.9959\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 18.7574 - mse: 18.7574 - val_loss: 19.7388 - val_mse: 19.7388\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 18.5323 - mse: 18.5323 - val_loss: 19.5170 - val_mse: 19.5170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5a44e72e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline non extremes\n",
    "\n",
    "m_null = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=False, for_lrp=True, **opt_model_new)\n",
    "\n",
    "# compile \n",
    "m_null.model.compile( loss='mse',  metrics=['mse'],  optimizer='adam')\n",
    "\n",
    "m_null.model.fit(dg_train_X_null, dg_train_Y, validation_data=(dg_valid_X_null, dg_valid_Y), \n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e5cbaa-3414-43f1-89d1-4c5a2844646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_null.model.save_weights('tmp/tmp_weights_DNN/UNET4_pr_NULL_linear_trained_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93747f96-9007-43b6-8c4c-eb50954bf627",
   "metadata": {},
   "source": [
    "#### Assess relevances (check the LRP_visualization notebook that uses other kernel)\n",
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b48d73-e754-4c49-9548-da91f2319259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
