{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d545b75d",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Import necessary modules and do some basic setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import datetime\n",
    "import math\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Dotenv\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41766d4a",
   "metadata": {},
   "source": [
    "### Define some paths and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Paths\n",
    "PATH_ERA5 = config['PATH_ERA5']\n",
    "PATH_EOBS = config['PATH_EOBS']\n",
    "\n",
    "# Some constants\n",
    "G = 9.80665 \n",
    "DATE_START = '1979-01-01'\n",
    "DATE_END = '2020-12-31'\n",
    "YY_TRAIN = [1979, 2015]\n",
    "YY_TEST = [2016, 2020]\n",
    "LEVELS = [500, 850, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3dbae",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74596028",
   "metadata": {},
   "source": [
    "## Target variable: precipitation field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abeea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation ERA5\n",
    "pr = get_era5_data(PATH_ERA5 + '/precipitation/day_grid1/*nc', DATE_START, DATE_END)\n",
    "\n",
    "# Define precipitation extremes using the 95th percentile\n",
    "pr95 = precip_exceedance_xarray(pr, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847649a",
   "metadata": {},
   "source": [
    "## Input data: meteorological fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geopotential height\n",
    "z = get_era5_data(PATH_ERA5 + '/geopotential/grid1/*.nc', DATE_START, DATE_END)\n",
    "z = z.sel(level=LEVELS)\n",
    "\n",
    "# Get Z in geopotential height (m)\n",
    "z.z.values = z.z.values/G\n",
    "\n",
    "# Get axes\n",
    "lats = z.lat\n",
    "lons = z.lon\n",
    "\n",
    "# Load temperature\n",
    "t2m = get_era5_data(PATH_ERA5 + '/temperature/grid1/Grid1_Daymean_era5_T2M_EU_19790101-20211231.nc',\n",
    "                    DATE_START, DATE_END)\n",
    "t2m['time'] = pd.DatetimeIndex(t2m.time.dt.date)\n",
    "t2m = t2m.rename_vars({'T2MMEAN': 't2m'})\n",
    "\n",
    "# Load relative humidity\n",
    "rh = get_era5_data(PATH_ERA5 + '/relative_humidity/day_grid1/*.nc',\n",
    "                   DATE_START, DATE_END)\n",
    "rh['time'] = pd.DatetimeIndex(rh.time.dt.date)\n",
    "rh = rh.sel(level=LEVELS)\n",
    "\n",
    "# Load wind components\n",
    "u850 = get_era5_data(PATH_ERA5 + '/U_wind/day_grid1/*.nc',\n",
    "                     DATE_START, DATE_END)\n",
    "u850['time'] = pd.DatetimeIndex(u850.time.dt.date)\n",
    "v850 = get_era5_data(PATH_ERA5 + '/V_wind/day_grid1/*.nc',\n",
    "                     DATE_START, DATE_END)\n",
    "v850['time'] = pd.DatetimeIndex(v850.time.dt.date)\n",
    "\n",
    "# Checking dimensions\n",
    "print('dimension of z', z.dims)\n",
    "print('dimension of t2m:', t2m.dims)\n",
    "print('dimension of rh:', rh.dims)\n",
    "print('dimension of u:', u850.dims)\n",
    "print('dimension of v:', v850.dims)\n",
    "print('dimension of pr:', pr.dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d54b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge arrays\n",
    "X = xr.merge([z, t2m, rh, u850, v850])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7643ef",
   "metadata": {},
   "source": [
    "### Split data and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23738ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test\n",
    "X_train_full = X.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]),\n",
    "                                '{}-12-31'.format(YY_TRAIN[1])))\n",
    "X_test = X.sel(time=slice('{}-01-01'.format(YY_TEST[0]),\n",
    "                          '{}-12-31'.format(YY_TEST[1])))\n",
    "\n",
    "pr_train_full = pr.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]),\n",
    "                                  '{}-12-31'.format(YY_TRAIN[1])))\n",
    "pr_test = pr.sel(time=slice('{}-01-01'.format(YY_TEST[0]),\n",
    "                            '{}-12-31'.format(YY_TEST[1])))\n",
    "xtr_train_full = pr95.sel(time=slice('{}-01-01'.format(YY_TRAIN[0]),\n",
    "                                     '{}-12-31'.format(YY_TRAIN[1])))\n",
    "xtr_test = pr95.sel(time=slice('{}-01-01'.format(YY_TEST[0]),\n",
    "                               '{}-12-31'.format(YY_TEST[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator\n",
    "dic = {'z': LEVELS,\n",
    "       't2m': None,\n",
    "       'r': LEVELS,\n",
    "       'u': None,\n",
    "       'v': None}\n",
    "\n",
    "dg_train = DataGenerator_extended(ds_train.sel(time=slice('1979', '2014')), dic, lead_time=0, batch_size=32, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full training into training and validation sets (and shuffle)\n",
    "X_train, X_valid, pr_train, pr_valid, xtr_train, xtr_valid = train_test_split(X_train_full, pr_train_full,\n",
    "                                                                              xtr_train_full,\n",
    "                                                                              test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82652338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True)\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "# Reshape data (set channel first; Con2D option data_format='channels_first' does not work on Win 10 64 bit)\n",
    "X_train = np.moveaxis(X_train, 1, -1)\n",
    "X_valid = np.moveaxis(X_valid, 1, -1)\n",
    "X_test = np.moveaxis(X_test, 1, -1)\n",
    "\n",
    "X_train.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
