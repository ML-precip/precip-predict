{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d545b75d",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Import necessary modules and do some basic setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import pathlib\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "#dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Dotenv\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daf9b9-8e6b-44e3-9763-11942a521ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_plot import *\n",
    "from utils.utils_RF import *\n",
    "#from utils.utils_ml import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41766d4a",
   "metadata": {},
   "source": [
    "### Define some paths and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Paths\n",
    "PATH_ERA5 = config['PATH_ERA5']\n",
    "PATH_EOBS = config['PATH_EOBS']\n",
    "\n",
    "# Some constants\n",
    "G = 9.80665\n",
    "\n",
    "# Options\n",
    "PRECIP_DATA = 'ERA5-low' # Options: ERA5-hi, ERA5-low, E-OBS\n",
    "DATE_START = '1979-01-01'\n",
    "DATE_END = '2021-12-31'\n",
    "YY_TRAIN = [1979, 2015]\n",
    "YY_TEST = [2016, 2021]\n",
    "LEVELS = [300, 500, 700, 850, 925, 1000]\n",
    "LONS_INPUT = [-25, 30]\n",
    "LATS_INPUT = [30, 75]\n",
    "LONS_PREC = [-25, 30]\n",
    "LATS_PREC = [30, 75]\n",
    "BATCH_SIZE = 64\n",
    "PRECIP_XTRM = 0.95 # Percentile (threshold) for the extremes\n",
    "CREATE_MASK_EOBS = False # only true when using E-OBS\n",
    "RF_MAX_DEPTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c274e-b72a-43c9-9ca0-be7cc16f1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample domain for dev\n",
    "#LONS_INPUT = [10, 15]\n",
    "#LATS_INPUT = [40, 45]\n",
    "#LONS_PREC = [10, 15]\n",
    "#LATS_PREC = [40, 45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3dbae",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74596028",
   "metadata": {},
   "source": [
    "## Target variable: precipitation field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa558b-faa9-45b5-9c91-35cce5fa09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precipitation\n",
    "if PRECIP_DATA == 'ERA5-hi':\n",
    "    pr = get_nc_data(PATH_ERA5 + '/precipitation/orig_grid/daily/*nc', DATE_START, DATE_END, LONS_PREC, LATS_PREC)\n",
    "    pr = pr.tp\n",
    "elif PRECIP_DATA == 'ERA5-low':\n",
    "    pr = get_nc_data(PATH_ERA5 + '/precipitation/day_grid1/*nc', DATE_START, DATE_END, LONS_PREC, LATS_PREC)\n",
    "    pr = pr.tp\n",
    "elif PRECIP_DATA in ['E-OBS', 'EOBS']:\n",
    "    pr = get_nc_data(PATH_EOBS + '/eobs_1deg_v26.0e.nc', DATE_START, DATE_END, LONS_PREC, LATS_PREC)\n",
    "    pr = pr.rr\n",
    "    CREATE_MASK_EOBS = True\n",
    "else:\n",
    "    raise ValueError('Precipitation data not well defined')\n",
    "pr['time'] = pd.DatetimeIndex(pr.time.dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e621bf-36da-4ee6-8d42-3b4758077c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert lat axis if needed\n",
    "if pr.lat[0].values < pr.lat[1].values:\n",
    "    pr = pr.reindex(lat=list(reversed(pr.lat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a98876-40d5-4301-878a-6a69d63df99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "mask = None\n",
    "if CREATE_MASK_EOBS:\n",
    "    if PRECIP_DATA in ['E-OBS', 'EOBS']:\n",
    "        peobs = pr\n",
    "    else:\n",
    "        peobs = get_nc_data(PATH_EOBS + '/eobs_1deg_v26.0e.nc', DATE_START, DATE_END, LONS_PREC, LATS_PREC)\n",
    "        peobs = peobs.rr\n",
    "        if peobs.lat[0].values < peobs.lat[1].values:\n",
    "            peobs = peobs.reindex(lat=list(reversed(peobs.lat)))\n",
    "    mask = np.isnan(peobs[0,:,:])\n",
    "    mask = np.invert(mask)\n",
    "    mask.plot()\n",
    "    mask = mask.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the extreme exceedence\n",
    "qq = xr.DataArray(pr).chunk(dict(time=-1)).quantile(PRECIP_XTRM, dim='time')\n",
    "pr_xtrm = xr.DataArray(pr > qq)\n",
    "pr_xtrm = pr_xtrm*1 # Transform to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47766a63-c892-4aad-a374-17c5caf3af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd208aba-31eb-42f2-a1b0-6d643b2ceadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates for precip\n",
    "lats_y = pr.lat.to_numpy()\n",
    "lons_y = pr.lon.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ea0f5-564e-4ad4-9eb4-ac78bc7d1fcd",
   "metadata": {},
   "source": [
    "## Input data: meteorological fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    # Load geopotential height\n",
    "    z = get_era5_data(PATH_ERA5 + '/geopotential/day_grid1/*.nc', DATE_START, DATE_END, LONS_INPUT, LATS_INPUT)\n",
    "    z['time'] = pd.DatetimeIndex(z.time.dt.date)\n",
    "    z = z.sel(level=LEVELS)\n",
    "\n",
    "    # Get Z in geopotential height (m)\n",
    "    z.z.values = z.z.values/G\n",
    "\n",
    "    # Load temperature\n",
    "    t = get_era5_data(PATH_ERA5 + '/temperature/day_grid1/*.nc', DATE_START, DATE_END, LONS_INPUT, LATS_INPUT)\n",
    "    t['time'] = pd.DatetimeIndex(t.time.dt.date)\n",
    "\n",
    "    # Load relative humidity\n",
    "    rh = get_era5_data(PATH_ERA5 + '/relative_humidity/day_grid1/*.nc', DATE_START, DATE_END, LONS_INPUT, LATS_INPUT)\n",
    "    rh['time'] = pd.DatetimeIndex(rh.time.dt.date)\n",
    "    rh = rh.sel(level=LEVELS)\n",
    "\n",
    "    # Load total column water\n",
    "    tcw = get_era5_data(PATH_ERA5 + '/total_column_water/day_grid1/*.nc', DATE_START, DATE_END, LONS_INPUT, LATS_INPUT)\n",
    "    tcw['time'] = pd.DatetimeIndex(tcw.time.dt.date)\n",
    "\n",
    "    # Load wind components\n",
    "    u = get_era5_data(PATH_ERA5 + '/U_wind/day_grid1/*.nc', DATE_START, DATE_END, LONS_INPUT, LATS_INPUT)\n",
    "    u['time'] = pd.DatetimeIndex(u.time.dt.date)\n",
    "    v = get_era5_data(PATH_ERA5 + '/V_wind/day_grid1/*.nc', DATE_START, DATE_END, LONS_INPUT, LATS_INPUT)\n",
    "    v['time'] = pd.DatetimeIndex(v.time.dt.date)\n",
    "\n",
    "# Checking dimensions\n",
    "print('dimension of pr:', pr.dims)\n",
    "print('dimension of z', z.dims)\n",
    "print('dimension of t:', t.dims)\n",
    "print('dimension of rh:', rh.dims)\n",
    "print('dimension of tcw:', tcw.dims)\n",
    "print('dimension of u:', u.dims)\n",
    "print('dimension of v:', v.dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82f636-3da7-4414-9619-0a57058b7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge arrays\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    X = xr.merge([z, t, rh, tcw, u, v])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a200bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert lat axis if needed\n",
    "if X.lat[0].values < X.lat[1].values:\n",
    "    X = X.reindex(lat=list(reversed(X.lat)))\n",
    "    \n",
    "# Get axes\n",
    "lats_x = X.lat\n",
    "lons_x = X.lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7643ef",
   "metadata": {},
   "source": [
    "### Split data and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23738ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test\n",
    "X_train_full = X.sel(time=slice(f'{YY_TRAIN[0]}-01-01', f'{YY_TRAIN[1]}-12-31'))\n",
    "X_test = X.sel(time=slice(f'{YY_TEST[0]}-01-01', f'{YY_TEST[1]}-12-31'))\n",
    "\n",
    "pr_train_full = pr.sel(time=slice(f'{YY_TRAIN[0]}-01-01', f'{YY_TRAIN[1]}-12-31'))\n",
    "pr_test = pr.sel(time=slice(f'{YY_TEST[0]}-01-01', f'{YY_TEST[1]}-12-31'))\n",
    "\n",
    "pr_xtrm_train_full = pr_xtrm.sel(time=slice(f'{YY_TRAIN[0]}-01-01', f'{YY_TRAIN[1]}-12-31'))\n",
    "pr_xtrm_test = pr_xtrm.sel(time=slice(f'{YY_TEST[0]}-01-01', f'{YY_TEST[1]}-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator\n",
    "dic = {'z': LEVELS,\n",
    "   't': LEVELS,\n",
    "   'r': LEVELS,\n",
    "   'tcwv': None,\n",
    "   'u': LEVELS,\n",
    "   'v': LEVELS}\n",
    "\n",
    "from utils.utils_ml import *\n",
    "\n",
    "YY_VALID = 2005\n",
    "# we might not need to split into valid\n",
    "dg_train = DataGeneratorWithExtremes(X_train_full.sel(time=slice(f'{YY_TRAIN[0]}', f'{YY_VALID}')),\n",
    "                                     pr_train_full.sel(time=slice(f'{YY_TRAIN[0]}', f'{YY_VALID}')),\n",
    "                                     pr_xtrm_train_full.sel(time=slice(f'{YY_TRAIN[0]}', f'{YY_VALID}')),\n",
    "                                     dic, batch_size=BATCH_SIZE, load=True)\n",
    "dg_valid = DataGeneratorWithExtremes(X_train_full.sel(time=slice(f'{YY_VALID+1}', f'{YY_TRAIN[1]}')),\n",
    "                                     pr_train_full.sel(time=slice(f'{YY_VALID+1}', f'{YY_TRAIN[1]}')),\n",
    "                                     pr_xtrm_train_full.sel(time=slice(f'{YY_VALID+1}', f'{YY_TRAIN[1]}')),\n",
    "                                     dic, mean=dg_train.mean, std=dg_train.std,\n",
    "                                     batch_size=BATCH_SIZE, load=True)\n",
    "dg_test = DataGeneratorWithExtremes(X_test, pr_test, pr_xtrm_test, dic,\n",
    "                                    mean=dg_train.mean, std=dg_train.std,\n",
    "                                    batch_size=BATCH_SIZE, load=True, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429afe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_shape = dg_train.X.shape\n",
    "o_shape = dg_train.y.shape\n",
    "\n",
    "print(f'X shape: {i_shape}')\n",
    "print(f'y shape: {o_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538787e-2f13-4e04-9581-2ce873c62fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = {'lon':5, 'lat':5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba7bd3",
   "metadata": {},
   "source": [
    "# Train a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039880c7-434a-4785-a0cc-529a42baadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dask = dg_train.X.chunk(chunk)\n",
    "y_train_dask = dg_train.y_xtrm.chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c916b9-a984-4bbd-bafb-14533a7d844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models file\n",
    "clf_file = f'tmp/trained_classifiers_RF_{PRECIP_DATA}_{PRECIP_XTRM}_{RF_MAX_DEPTH}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fab24d-3ffe-4eae-9199-4138919e0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(clf_file):\n",
    "    print('open models')\n",
    "    #open models\n",
    "    with open(clf_file, 'rb') as f:\n",
    "        crfs = pickle.load(f)\n",
    "else:\n",
    "    \n",
    "#%%time\n",
    "    crfs = xr.apply_ufunc(\n",
    "        train_rf_classifier_model,\n",
    "        X_train_dask, y_train_dask, RF_MAX_DEPTH,\n",
    "        vectorize=True,\n",
    "        dask = 'parallelized',\n",
    "        input_core_dims=[['time', 'level'], ['time'], []],  # reduce along these dimensions\n",
    "        output_dtypes=[object]\n",
    "    ).compute()\n",
    "    # save the models\n",
    "    with open(clf_file, 'wb') as output:\n",
    "            pickle.dump(crfs, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76b264-7fc4-4d06-a5a3-ddb357714d1f",
   "metadata": {},
   "source": [
    "### Predict for the testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbcd3d0-a7eb-4539-b413-c1c3a346d923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_test_preds = xr.apply_ufunc(\n",
    "    apply_rf_classifier_model, \n",
    "    crfs, dg_test.X,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level']],\n",
    "    output_dtypes=['object'] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5882e-dd03-4a16-b9d0-960013054013",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_test_preds_proba = xr.apply_ufunc(\n",
    "    apply_rf_classifier_model_proba, \n",
    "    crfs, dg_test.X,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level']],\n",
    "    output_dtypes=['object'] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421df2da-74b4-4ce1-a6af-a82dbf2860bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train_preds = xr.apply_ufunc(\n",
    "    apply_rf_classifier_model, \n",
    "    crfs, dg_train.X,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level']],\n",
    "    output_dtypes=['object'] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b46dea-4891-4718-8b33-9ce4fe5d2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Xarray with the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7cd3c-d432-4b85-8da0-2e72a8cb17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xtrm_test = create_xarray_frompred(y_test_preds, dg_test.y.shape[0], lats_y, lons_x)\n",
    "yprob_pred_xtrm_test = create_xarray_frompred(y_test_preds_proba, dg_test.y.shape[0], lats_y, lons_x)\n",
    "y_pred_xtrm_train = create_xarray_frompred(y_train_preds, dg_train.y.shape[0], lats_y, lons_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aeaead-e998-4f9a-90e1-4d0abca20c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as an example\n",
    "y_pred_xtrm_test[800,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ebb3b-de57-431f-a262-37183af3ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yprob_pred_xtrm_test[800,:,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5ad95-eab9-43f3-be26-38850f5d8382",
   "metadata": {},
   "source": [
    "#### Calculate scores (these are also calculated later in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ec5ba-6928-4c8b-8c95-0e0ea8de6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "auc = xr.apply_ufunc(\n",
    "    eval_rf_auc, \n",
    "    crfs, dg_test.X,dg_test.y_xtrm,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level'],['time']],\n",
    "    output_core_dims=[[]],\n",
    "    output_dtypes=[float] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109716b-a33c-4de2-8093-f098d3e9a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "precision = xr.apply_ufunc(\n",
    "    eval_rf_precision, \n",
    "    crfs, dg_test.X,dg_test.y_xtrm,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level'],['time']],\n",
    "    output_core_dims=[[]],\n",
    "    output_dtypes=[float] # change the output type\n",
    ").compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a38224-a0f7-4d5e-ad4b-2bad62c622de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "recall = xr.apply_ufunc(\n",
    "    eval_rf_recall, \n",
    "    crfs, dg_test.X,dg_test.y_xtrm,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level'],['time']],\n",
    "    output_core_dims=[[]],\n",
    "    output_dtypes=[float] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15022f34-111a-40a7-95dc-c4d070892dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mask before plotting if data is E-OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470dd20-7c02-4184-a40c-8694eaf2a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(mask, metric):\n",
    "    \"\"\"filter with the mask\"\"\"\n",
    "    nan_mask=mask*1.0\n",
    "    nan_mask[mask==0]=np.nan\n",
    "    \n",
    "    return(metric*nan_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3923d59-0daa-4488-8bd2-fac42c249d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_MASK_EOBS:\n",
    "    precision = filter_mask(mask, precision)\n",
    "    recall = filter_mask(mask, recall)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1cb9e-1bfa-425c-a9aa-ddd2efa7b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb9fd8-4c88-49d3-9f78-b15f08f77e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(24, 3.5), ncols=3, nrows=1)\n",
    "plot_map(axes[0], lons_y, lats_y, auc, title=\"AUC\", vmin=0, vmax=1)\n",
    "plot_map(axes[1], lons_y, lats_y, precision, title=\"precision\", vmin=0, vmax=1)\n",
    "plot_map(axes[2], lons_y, lats_y, recall, title=\"recall\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec9182-1330-47d9-b08e-be83cb20f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics-Spatially averages \n",
    "metrics_prec_xtrm = pd.DataFrame([(auc.mean().values, recall.mean().values, precision.mean().values)], columns=['auc', 'recall', 'precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c265f-9e89-4414-818d-15f6832d4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RF-averages scores:')\n",
    "print(metrics_prec_xtrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da6fae-26cb-426b-a00d-2ad1ec02a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape predictions to create maps\n",
    "#preds_reshaped = np.zeros(dg_test.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7387b-797d-4ed1-98a2-13b15e85fcff",
   "metadata": {},
   "source": [
    "# Train a random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d57a0a-6362-46ee-bfa9-a3a32265b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt similar functions to the classification case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c158faa-53aa-44f2-9877-ee542a72e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dask = dg_train.X.chunk(chunk)\n",
    "y_train_dask = dg_train.y.chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ea583-14e7-4d21-bc7e-191cd806a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models file\n",
    "rfs_file = f'tmp/trained_regressors_RF_{PRECIP_DATA}_{PRECIP_XTRM}_{RF_MAX_DEPTH}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee93b49-09b6-4af5-9c4b-e6601375ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf_regress_model(X, y, max_depth=4):\n",
    "    if np.any(np.isnan(y)):\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        rgf =  RandomForestRegressor(max_depth=max_depth, random_state=42).fit(X, y)\n",
    "        #clf.fit(X, y)\n",
    "        print('|', end='')\n",
    "        return rgf\n",
    "    except:\n",
    "        #print('Failed to create the model')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1f94d-50f2-4105-85df-1a343e0159bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(rfs_file):\n",
    "    #print('open models')\n",
    "    #open models\n",
    "    with open(rfs_file, 'rb') as f:\n",
    "        rfs = pickle.load(f)\n",
    "else:\n",
    "    \n",
    "    rfs = xr.apply_ufunc(\n",
    "        train_rf_regress_model,\n",
    "        X_train_dask, y_train_dask, RF_MAX_DEPTH,\n",
    "        vectorize=True,\n",
    "        dask = 'parallelized',\n",
    "        input_core_dims=[['time', 'level'], ['time'], []],  # reduce along these dimensions\n",
    "        output_dtypes=[object]\n",
    "    ).compute()\n",
    "    # save the models\n",
    "    with open(rfs_file, 'wb') as output:\n",
    "            pickle.dump(rfs, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8622c-c259-457f-8788-32ce76195813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "y_test_preds_reg = xr.apply_ufunc(\n",
    "    apply_rf_regress_model, \n",
    "    rfs, dg_test.X,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level']],\n",
    "    output_core_dims=[[]],\n",
    "    output_dtypes=[object] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfb3b6-cb12-4b42-920b-1b9411796209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "y_train_preds_reg = xr.apply_ufunc(\n",
    "    apply_rf_regress_model, \n",
    "    rfs, dg_train.X,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level']],\n",
    "    output_core_dims=[[]],\n",
    "    output_dtypes=[object] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c21c8c-2f02-46ef-98c9-0dbcbcf306d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of predictions\n",
    "preds_test_reg_matrix = create_xarray_frompred(y_test_preds_reg, dg_test.y.shape[0], lats_y, lons_x)\n",
    "preds_train_reg_matrix = create_xarray_frompred(y_train_preds_reg, dg_train.y.shape[0], lats_y, lons_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bec9b-4197-482f-acff-9f1973cf635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_reg_matrix[800,:,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad291d-cddd-462c-8968-699dda24b09e",
   "metadata": {},
   "source": [
    "#### calculate rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2446d-507b-44aa-a67c-ef1592131532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate--check --not working\n",
    "rmse = xr.apply_ufunc(\n",
    "    eval_rf_mse, \n",
    "    rfs, dg_test.X,dg_test.y,\n",
    "    vectorize=True,\n",
    "    input_core_dims=[[],['time', 'level'],['time']],\n",
    "    #output_core_dims=[[]],\n",
    "   # output_dtypes=[object] # change the output type\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac8796-61e7-43e8-92ab-71777aafadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12, 6), ncols=1, nrows=1)\n",
    "plot_map(axes, lons_y, lats_y, rmse, title=\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9cb57-dd28-4fe4-bf17-fbee35ac4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial average of MSE\n",
    "# Metrics-Spatially averages \n",
    "rmse.mean().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e58ba8-5307-489c-9a92-25b2b7e0bbd1",
   "metadata": {},
   "source": [
    "# Predict and assess on the test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810b13b-4d2e-439d-af81-8dcf46390706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the amount of precipitation\n",
    "df_prec = pd.DataFrame(columns = ['id', 'name',\n",
    "                                  'train_pr_rmse', 'test_pr_rmse', \n",
    "                                  'train_xtrm_precision', 'test_xtrm_precision', \n",
    "                                  'train_xtrm_recall', 'test_xtrm_recall'],index=[1])\n",
    "df_prec.at[df_prec.index[0], 'id'] = 'RF'\n",
    "df_prec.at[df_prec.index[0], 'name'] = 'Regressor'\n",
    "df_xtrm = pd.DataFrame(columns = ['id', 'name', \n",
    "                                  'train_xtrm_roc_auc', 'test_xtrm_roc_auc', \n",
    "                                  'train_xtrm_precision', 'test_xtrm_precision', \n",
    "                                  'train_xtrm_recall', 'test_xtrm_recall'],index=[1])\n",
    "df_xtrm.at[df_xtrm.index[0], 'id'] = 'RF'\n",
    "df_xtrm.at[df_xtrm.index[0], 'name'] = 'Classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88a51a-6895-4bc2-b287-c358de4d3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Result for precipitation amounts, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ef4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "apply_for_prec = True\n",
    "\n",
    "if apply_for_prec:\n",
    "    print('Train results')\n",
    "    precision_train, recall_train, rmse_train = analyze_predictions(preds_train_reg_matrix, dg_train, qq, lons_y, lats_y, pred_xtrm=False, show_plots=False)\n",
    "    df_prec.at[df_prec.index[0], 'train_xtrm_precision'] = precision_train\n",
    "    df_prec.at[df_prec.index[0], 'train_xtrm_recall'] = recall_train\n",
    "    df_prec.at[df_prec.index[0], 'train_pr_rmse'] = rmse_train\n",
    "    print('Test results')\n",
    "    precision, recall, rmse = analyze_predictions(preds_test_reg_matrix, dg_test, qq, lons_y, lats_y, pred_xtrm=False, show_plots=False)\n",
    "    df_prec.at[df_prec.index[0], 'test_xtrm_precision'] = precision\n",
    "    df_prec.at[df_prec.index[0], 'test_xtrm_recall'] = recall\n",
    "    df_prec.at[df_prec.index[0], 'test_pr_rmse'] = rmse\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e74ea-aefa-47cd-a27a-31c515f3fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ce6fa-5833-4e22-9aa3-1749eb83f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Result for precipitation extremes, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bda0b-ea3c-402e-b34b-be919f919355",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_for_xtrm = True\n",
    "\n",
    "if apply_for_xtrm:\n",
    "    print('Train results')\n",
    "    precision_train, recall_train, auc_train = analyze_predictions(y_pred_xtrm_train, dg_train, qq, lons_y, lats_y, pred_xtrm=True, show_plots=False)\n",
    "    df_xtrm.at[df_xtrm.index[-1], 'train_xtrm_precision'] = precision_train\n",
    "    df_xtrm.at[df_xtrm.index[-1], 'train_xtrm_recall'] = recall_train\n",
    "    df_xtrm.at[df_xtrm.index[-1], 'train_xtrm_roc_auc'] = auc_train\n",
    "\n",
    "    print('Test results')\n",
    "    precision, recall, auc = analyze_predictions(y_pred_xtrm_test, dg_test, qq, lons_y, lats_y, pred_xtrm=True, show_plots=False)\n",
    "    df_xtrm.at[df_xtrm.index[-1], 'test_xtrm_precision'] = precision\n",
    "    df_xtrm.at[df_xtrm.index[-1], 'test_xtrm_recall'] = recall\n",
    "    df_xtrm.at[df_xtrm.index[-1], 'test_xtrm_roc_auc'] = auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976cd93-3198-40d5-b362-84876b0dc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172770a0-470a-4b8b-93d5-26fe9da0d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fig.1 and 2 but only using truth and RF\n",
    "n_rows = 2\n",
    "m_id = \"RF\"\n",
    "fig, axs = plt.subplots(n_rows, 3, figsize=(10, n_rows*3))\n",
    "# For the model take predictions\n",
    "y_pred = preds_test_reg_matrix\n",
    "y_pred_bool = y_pred > qq.to_numpy().squeeze()\n",
    "\n",
    "# Extract true values\n",
    "y_xtrm = dg_test.y_xtrm.to_numpy().squeeze()\n",
    "y_prec = dg_test.y.to_numpy().squeeze()\n",
    "\n",
    "# Get the index of the max # of extremes\n",
    "i_max_obs = np.argmax(np.sum(y_xtrm, axis=(1,2)))\n",
    "\n",
    "vmax = np.max(y_prec[i_max_obs])\n",
    "\n",
    "plot_map(axs[0, 0], lons_y, lats_y, y_prec[i_max_obs], title=\"Prec. value - truth\", vmin=0, vmax=vmax, show_colorbar=False, cmap=mpl.cm.YlGnBu)\n",
    "plot_map(axs[0, 1], lons_y, lats_y, y_xtrm[i_max_obs], title=\"Prec. extreme - truth\", vmin=0, vmax=1, show_colorbar=False)\n",
    "plot_map(axs[0, 2], lons_y, lats_y, y_xtrm[i_max_obs], title=\"Prec. extreme - truth\", vmin=0, vmax=1, show_colorbar=False)\n",
    "\n",
    "\n",
    "# Plot the model\n",
    "plot_map(axs[1, 0], lons_y, lats_y, y_pred[i_max_obs], title=f\"Prec. value - {m_id}\", vmin=0, vmax=vmax, show_colorbar=False, cmap=mpl.cm.YlGnBu)\n",
    "plot_map(axs[1, 1], lons_y, lats_y, y_pred_bool[i_max_obs], title=f\"Prec. extreme - {m_id}\", vmin=0, vmax=1, show_colorbar=False)\n",
    "plot_map(axs[1, 2], lons_y, lats_y, yprob_pred_xtrm_test[i_max_obs], title=f\"Prec. extreme - {m_id}\", vmin=0, vmax=1, show_colorbar=False)\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/plot_model_RF95th_comparison.pdf')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
