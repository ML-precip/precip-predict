{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d545b75d",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Import necessary modules and do some basic setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1427bd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.0'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import pathlib\n",
    "import hashlib\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Dotenv\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Custom utils\n",
    "from utils.utils_data import *\n",
    "from utils.utils_ml import *\n",
    "from utils.utils_resnet import *\n",
    "from utils.utils_plot import *\n",
    "from utils.DNN_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a538e73-d554-464b-8b56-9f2690110750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "conf = yaml.safe_load(open(\"config.yaml\"))\n",
    "PRECIP_XTRM = 0.99 # Percentile (threshold) for the extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e326642-b002-4e29-a8be-3740c2b2a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: [46, 56, 31]\n",
      "y shape: [46, 56, 1]\n"
     ]
    }
   ],
   "source": [
    "i_shape = conf['i_shape']\n",
    "o_shape = conf['o_shape']\n",
    "\n",
    "print(f'X shape: {i_shape}')\n",
    "print(f'y shape: {o_shape}')\n",
    "output_channels = conf['output_channels']\n",
    "num_filters = conf['num_filters']\n",
    "use_batchnorm = conf['use_batchnorm']\n",
    "dropout = conf['dropout']\n",
    "lr = conf['lr']\n",
    "\n",
    "name_model = conf['model']\n",
    "output_scaling = 1\n",
    "output_crop = None\n",
    "\n",
    "\n",
    "# load coordinates\n",
    "lons_x = np.load('tmp/data/lons_y.npy')\n",
    "lats_y = np.load('tmp/data/lats_y.npy')\n",
    "\n",
    "# load precip\n",
    "if PRECIP_XTRM == 0.95:\n",
    "    pr_xtrm = np.load('tmp/data/pr_xtrm_95.npy')\n",
    "elif PRECIP_XTRM == 0.99:\n",
    "    pr_xtrm = np.load('tmp/data/pr_xtrm_99.npy')\n",
    "#pr_xtrm = np.load('tmp/data/pr_xtrm_99.npy')\n",
    "# create a time array\n",
    "times = np.arange(np.datetime64('1979-01-01'), np.datetime64('2006-01-01')) #until validation period\n",
    "times = pd.to_datetime(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e21f09-2b6a-488a-a2fb-bb9a7d0c336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing data\n",
    "dg_train_X = np.array(xr.open_dataarray('tmp/data/dg_train_X.nc'))\n",
    "dg_train_Y = np.array(xr.open_dataarray('tmp/data/dg_train_Y.nc'))\n",
    "\n",
    "dg_valid_X = np.array(xr.open_dataarray('tmp/data/dg_valid_X.nc'))\n",
    "dg_valid_Y = np.array(xr.open_dataarray('tmp/data/dg_valid_Y.nc'))\n",
    "\n",
    "\n",
    "test_times = np.arange(np.datetime64('2016-01-01'), np.datetime64('2022-01-01')) #until validation period\n",
    "test_times = pd.to_datetime(test_times)\n",
    "dg_test_X = np.array(xr.open_dataarray('tmp/data/dg_test_X.nc'))\n",
    "dg_test_Y = np.array(xr.open_dataarray('tmp/data/dg_test_Y.nc'))\n",
    "\n",
    "# Open files for extremes\n",
    "if PRECIP_XTRM == 0.95:\n",
    "    dg_train_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_train_Y_xtrm0.95th.nc'))\n",
    "    dg_valid_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_valid_Y_xtrm0.95th.nc')) \n",
    "    dg_test_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_test_Y_xtrm0.95th.nc'))\n",
    "elif PRECIP_XTRM == 0.99:\n",
    "    dg_train_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_train_Y_xtrm0.99th.nc'))\n",
    "    dg_valid_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_valid_Y_xtrm0.99th.nc')) \n",
    "    dg_test_Y_xtrm = np.array(xr.open_dataarray('tmp/data/dg_test_Y_xtrm0.99th.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53125a84-f898-4094-87de-af796bd97c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pass zeros through the network to asses the baseline\n",
    "dg_train_X_null = np.zeros(dg_train_X.shape)\n",
    "dg_valid_X_null = np.zeros(dg_valid_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9935660-db52-48de-9296-50595b3de7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for the weighted binary crossentropy:\n",
      "Classes: [0 1], weights: [ 0.50508104 49.70253165]\n"
     ]
    }
   ],
   "source": [
    "# Compute weights for the weighted binary crossentropy\n",
    "weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(pr_xtrm),\n",
    "    y=pr_xtrm.flatten()\n",
    ")\n",
    "\n",
    "print('Weights for the weighted binary crossentropy:')\n",
    "print(f'Classes: {np.unique(pr_xtrm)}, weights: {weights}')\n",
    "\n",
    "# Create loss function for the extremes\n",
    "xtrm_loss = weighted_binary_cross_entropy(\n",
    "    weights={0: weights[0].astype('float32'), 1: weights[1].astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc1d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "LR_METHOD = 'Constant'  # Cyclical, CosineDecay, Constant\n",
    "                                            \n",
    "# Default model options\n",
    "opt_model = {'latent_dim': 128,\n",
    "             'dropout_rate': 0.2}\n",
    "\n",
    "# Default optimizer options\n",
    "opt_optimizer = {'lr_method': 'Constant',\n",
    "                 'lr': 0.0004,\n",
    "                 'init_lr': 0.01}\n",
    "\n",
    "models = {\n",
    "          'UNET1': {'model': 'Unet', 'run': True,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 1, 'unet_use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET2': {'model': 'Unet', 'run': True,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 2, 'unet_use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET3': {'model': 'Unet', 'run': True,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 3, 'unet_use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET4': {'model': 'Unet', 'run': True,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 4, 'unet_use_upsample': True},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET-att': {'model': 'Unet-attention', 'run': True,\n",
    "                   'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop},\n",
    "                   'opt_optimizer': {'lr_method': 'Constant'}},\n",
    "          'UNET1-att': {'model': 'Unet-attention', 'run': True,\n",
    "                       'opt_model': {'output_scaling': output_scaling, 'output_crop': output_crop, 'unet_depth': 1, 'unet_use_upsample': True},\n",
    "                       'opt_optimizer': {'lr_method': 'Constant'}}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd109fd-c561-44ac-8fc4-f1277f8844c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############LRP ###########\n",
    "EPOCHS = 50\n",
    "m_id = 'UNET4'\n",
    "model = models[m_id]['model']\n",
    "opt_model_i = models[m_id]['opt_model']\n",
    "opt_optimizer_i = models[m_id]['opt_optimizer']\n",
    "\n",
    "opt_model_new = opt_model.copy()\n",
    "opt_model_new.update(opt_model_i)\n",
    "opt_optimizer_new = opt_optimizer.copy()\n",
    "opt_optimizer_new.update(opt_optimizer_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bdd258e-0af1-4c74-8b41-d2ce63f4e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 16:13:28.301400: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-15 16:13:29.030485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Extremes\n",
    "m = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=True,**opt_model_new)\n",
    "\n",
    "# compile \n",
    "m.model.compile(loss=keras.losses.categorical_crossentropy, ## instead of CategoricalCrossentropy\n",
    "                  optimizer='adam', ## lr instead of learning_rate\n",
    "                  metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1183a095-6d46-4f43-a0e2-0618e2917280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 16:13:39.437892: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb870de50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train \n",
    "m.model.fit(dg_train_X_null, dg_train_Y_xtrm, validation_data=(dg_valid_X_null, dg_valid_Y_xtrm), \n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a495bdc0-fc28-4433-9b28-4e9627a67d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model.save_weights('tmp/tmp_weights_DNN/UNET4_NULL_0.99th_trained_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "451288bf-8449-4d11-a2c3-de7fb90caa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 15:54:24.431420: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-15 15:54:25.160438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Not extremes\n",
    "m_pr = DeepFactory_Keras(model, i_shape, o_shape, for_extremes=False,**opt_model_new)\n",
    "\n",
    "# compile \n",
    "m_pr.model.compile( loss='mse',  metrics=['mse'],  optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eabaeff-d15e-4a8a-ab16-1d59e2fcec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 15:54:35.594467: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd76e2b24f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pr.model.fit(dg_train_X_null, dg_train_Y, validation_data=(dg_valid_X_null, dg_valid_Y), \n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4c4b6c7-1140-400f-864d-f052ddf3770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pr.model.save_weights('tmp/tmp_weights_DNN/UNET4_NULL_pr_trained_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
